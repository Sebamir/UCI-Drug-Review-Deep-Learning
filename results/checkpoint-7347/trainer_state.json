{
  "best_global_step": 7347,
  "best_metric": 0.30750659108161926,
  "best_model_checkpoint": "./results\\checkpoint-7347",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 7347,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006805498843065197,
      "grad_norm": 1.5159518718719482,
      "learning_rate": 1.9600000000000003e-06,
      "loss": 0.6973,
      "step": 50
    },
    {
      "epoch": 0.013610997686130393,
      "grad_norm": 1.6247541904449463,
      "learning_rate": 3.96e-06,
      "loss": 0.6888,
      "step": 100
    },
    {
      "epoch": 0.02041649652919559,
      "grad_norm": 1.6273103952407837,
      "learning_rate": 5.9600000000000005e-06,
      "loss": 0.691,
      "step": 150
    },
    {
      "epoch": 0.027221995372260787,
      "grad_norm": 2.6355791091918945,
      "learning_rate": 7.960000000000002e-06,
      "loss": 0.676,
      "step": 200
    },
    {
      "epoch": 0.034027494215325985,
      "grad_norm": 12.368112564086914,
      "learning_rate": 9.960000000000001e-06,
      "loss": 0.6244,
      "step": 250
    },
    {
      "epoch": 0.04083299305839118,
      "grad_norm": 13.105323791503906,
      "learning_rate": 1.196e-05,
      "loss": 0.4941,
      "step": 300
    },
    {
      "epoch": 0.04763849190145638,
      "grad_norm": 10.698094367980957,
      "learning_rate": 1.396e-05,
      "loss": 0.5225,
      "step": 350
    },
    {
      "epoch": 0.054443990744521574,
      "grad_norm": 3.234046459197998,
      "learning_rate": 1.5960000000000003e-05,
      "loss": 0.3701,
      "step": 400
    },
    {
      "epoch": 0.06124948958758677,
      "grad_norm": 4.896227836608887,
      "learning_rate": 1.796e-05,
      "loss": 0.4916,
      "step": 450
    },
    {
      "epoch": 0.06805498843065197,
      "grad_norm": 15.69320011138916,
      "learning_rate": 1.9960000000000002e-05,
      "loss": 0.5108,
      "step": 500
    },
    {
      "epoch": 0.07486048727371716,
      "grad_norm": 15.873366355895996,
      "learning_rate": 1.985687162260844e-05,
      "loss": 0.5418,
      "step": 550
    },
    {
      "epoch": 0.08166598611678236,
      "grad_norm": 5.847702503204346,
      "learning_rate": 1.971082225792318e-05,
      "loss": 0.4685,
      "step": 600
    },
    {
      "epoch": 0.08847148495984755,
      "grad_norm": 11.632272720336914,
      "learning_rate": 1.9564772893237916e-05,
      "loss": 0.4045,
      "step": 650
    },
    {
      "epoch": 0.09527698380291276,
      "grad_norm": 1.03879714012146,
      "learning_rate": 1.9418723528552652e-05,
      "loss": 0.3827,
      "step": 700
    },
    {
      "epoch": 0.10208248264597795,
      "grad_norm": 8.439698219299316,
      "learning_rate": 1.927267416386739e-05,
      "loss": 0.4633,
      "step": 750
    },
    {
      "epoch": 0.10888798148904315,
      "grad_norm": 2.1789608001708984,
      "learning_rate": 1.9126624799182125e-05,
      "loss": 0.4769,
      "step": 800
    },
    {
      "epoch": 0.11569348033210834,
      "grad_norm": 35.57274627685547,
      "learning_rate": 1.898057543449686e-05,
      "loss": 0.4474,
      "step": 850
    },
    {
      "epoch": 0.12249897917517354,
      "grad_norm": 6.45993709564209,
      "learning_rate": 1.8834526069811597e-05,
      "loss": 0.3794,
      "step": 900
    },
    {
      "epoch": 0.12930447801823874,
      "grad_norm": 8.644003868103027,
      "learning_rate": 1.8688476705126336e-05,
      "loss": 0.4992,
      "step": 950
    },
    {
      "epoch": 0.13610997686130394,
      "grad_norm": 11.617646217346191,
      "learning_rate": 1.8542427340441072e-05,
      "loss": 0.3699,
      "step": 1000
    },
    {
      "epoch": 0.14291547570436913,
      "grad_norm": 24.208213806152344,
      "learning_rate": 1.8396377975755805e-05,
      "loss": 0.4602,
      "step": 1050
    },
    {
      "epoch": 0.14972097454743433,
      "grad_norm": 8.73907470703125,
      "learning_rate": 1.825032861107054e-05,
      "loss": 0.4083,
      "step": 1100
    },
    {
      "epoch": 0.15652647339049952,
      "grad_norm": 13.574980735778809,
      "learning_rate": 1.810427924638528e-05,
      "loss": 0.4216,
      "step": 1150
    },
    {
      "epoch": 0.16333197223356472,
      "grad_norm": 33.325660705566406,
      "learning_rate": 1.7958229881700017e-05,
      "loss": 0.3537,
      "step": 1200
    },
    {
      "epoch": 0.1701374710766299,
      "grad_norm": 17.229875564575195,
      "learning_rate": 1.7812180517014753e-05,
      "loss": 0.3805,
      "step": 1250
    },
    {
      "epoch": 0.1769429699196951,
      "grad_norm": 15.635741233825684,
      "learning_rate": 1.766613115232949e-05,
      "loss": 0.4829,
      "step": 1300
    },
    {
      "epoch": 0.1837484687627603,
      "grad_norm": 25.553424835205078,
      "learning_rate": 1.7520081787644225e-05,
      "loss": 0.3666,
      "step": 1350
    },
    {
      "epoch": 0.19055396760582552,
      "grad_norm": 1.4893337488174438,
      "learning_rate": 1.737403242295896e-05,
      "loss": 0.429,
      "step": 1400
    },
    {
      "epoch": 0.1973594664488907,
      "grad_norm": 14.57003116607666,
      "learning_rate": 1.7227983058273697e-05,
      "loss": 0.3682,
      "step": 1450
    },
    {
      "epoch": 0.2041649652919559,
      "grad_norm": 2.208310127258301,
      "learning_rate": 1.7081933693588436e-05,
      "loss": 0.3582,
      "step": 1500
    },
    {
      "epoch": 0.2109704641350211,
      "grad_norm": 18.766036987304688,
      "learning_rate": 1.6935884328903172e-05,
      "loss": 0.3781,
      "step": 1550
    },
    {
      "epoch": 0.2177759629780863,
      "grad_norm": 14.8903169631958,
      "learning_rate": 1.6789834964217905e-05,
      "loss": 0.3486,
      "step": 1600
    },
    {
      "epoch": 0.2245814618211515,
      "grad_norm": 2.5545852184295654,
      "learning_rate": 1.664378559953264e-05,
      "loss": 0.4144,
      "step": 1650
    },
    {
      "epoch": 0.23138696066421668,
      "grad_norm": 27.299835205078125,
      "learning_rate": 1.649773623484738e-05,
      "loss": 0.4302,
      "step": 1700
    },
    {
      "epoch": 0.23819245950728188,
      "grad_norm": 15.120465278625488,
      "learning_rate": 1.6351686870162117e-05,
      "loss": 0.3884,
      "step": 1750
    },
    {
      "epoch": 0.24499795835034707,
      "grad_norm": 8.425512313842773,
      "learning_rate": 1.6205637505476853e-05,
      "loss": 0.4248,
      "step": 1800
    },
    {
      "epoch": 0.2518034571934123,
      "grad_norm": 9.405450820922852,
      "learning_rate": 1.605958814079159e-05,
      "loss": 0.3611,
      "step": 1850
    },
    {
      "epoch": 0.2586089560364775,
      "grad_norm": 25.67142677307129,
      "learning_rate": 1.5913538776106325e-05,
      "loss": 0.4619,
      "step": 1900
    },
    {
      "epoch": 0.2654144548795427,
      "grad_norm": 10.516976356506348,
      "learning_rate": 1.576748941142106e-05,
      "loss": 0.3874,
      "step": 1950
    },
    {
      "epoch": 0.2722199537226079,
      "grad_norm": 55.56032180786133,
      "learning_rate": 1.5621440046735797e-05,
      "loss": 0.3409,
      "step": 2000
    },
    {
      "epoch": 0.27902545256567307,
      "grad_norm": 32.596920013427734,
      "learning_rate": 1.5475390682050536e-05,
      "loss": 0.3532,
      "step": 2050
    },
    {
      "epoch": 0.28583095140873827,
      "grad_norm": 10.50125503540039,
      "learning_rate": 1.5329341317365273e-05,
      "loss": 0.4506,
      "step": 2100
    },
    {
      "epoch": 0.29263645025180346,
      "grad_norm": 0.2980659604072571,
      "learning_rate": 1.5183291952680005e-05,
      "loss": 0.3757,
      "step": 2150
    },
    {
      "epoch": 0.29944194909486865,
      "grad_norm": 9.720233917236328,
      "learning_rate": 1.5037242587994743e-05,
      "loss": 0.3617,
      "step": 2200
    },
    {
      "epoch": 0.30624744793793385,
      "grad_norm": 17.361682891845703,
      "learning_rate": 1.4891193223309479e-05,
      "loss": 0.4084,
      "step": 2250
    },
    {
      "epoch": 0.31305294678099904,
      "grad_norm": 7.777543067932129,
      "learning_rate": 1.4745143858624215e-05,
      "loss": 0.3973,
      "step": 2300
    },
    {
      "epoch": 0.31985844562406424,
      "grad_norm": 8.322490692138672,
      "learning_rate": 1.4599094493938953e-05,
      "loss": 0.3736,
      "step": 2350
    },
    {
      "epoch": 0.32666394446712943,
      "grad_norm": 9.149131774902344,
      "learning_rate": 1.4453045129253689e-05,
      "loss": 0.3719,
      "step": 2400
    },
    {
      "epoch": 0.3334694433101946,
      "grad_norm": 1.4335006475448608,
      "learning_rate": 1.4306995764568425e-05,
      "loss": 0.3713,
      "step": 2450
    },
    {
      "epoch": 0.3402749421532598,
      "grad_norm": 44.450923919677734,
      "learning_rate": 1.4160946399883163e-05,
      "loss": 0.3254,
      "step": 2500
    },
    {
      "epoch": 0.347080440996325,
      "grad_norm": 27.548234939575195,
      "learning_rate": 1.4014897035197899e-05,
      "loss": 0.4207,
      "step": 2550
    },
    {
      "epoch": 0.3538859398393902,
      "grad_norm": 24.772335052490234,
      "learning_rate": 1.3868847670512635e-05,
      "loss": 0.2849,
      "step": 2600
    },
    {
      "epoch": 0.3606914386824554,
      "grad_norm": 14.374735832214355,
      "learning_rate": 1.3722798305827371e-05,
      "loss": 0.4017,
      "step": 2650
    },
    {
      "epoch": 0.3674969375255206,
      "grad_norm": 46.96462631225586,
      "learning_rate": 1.3576748941142105e-05,
      "loss": 0.3373,
      "step": 2700
    },
    {
      "epoch": 0.37430243636858584,
      "grad_norm": 12.339396476745605,
      "learning_rate": 1.3430699576456843e-05,
      "loss": 0.3901,
      "step": 2750
    },
    {
      "epoch": 0.38110793521165104,
      "grad_norm": 16.225257873535156,
      "learning_rate": 1.328465021177158e-05,
      "loss": 0.3077,
      "step": 2800
    },
    {
      "epoch": 0.38791343405471623,
      "grad_norm": 7.628223896026611,
      "learning_rate": 1.3138600847086315e-05,
      "loss": 0.4776,
      "step": 2850
    },
    {
      "epoch": 0.3947189328977814,
      "grad_norm": 3.7334296703338623,
      "learning_rate": 1.2992551482401053e-05,
      "loss": 0.3425,
      "step": 2900
    },
    {
      "epoch": 0.4015244317408466,
      "grad_norm": 26.310470581054688,
      "learning_rate": 1.2846502117715789e-05,
      "loss": 0.3237,
      "step": 2950
    },
    {
      "epoch": 0.4083299305839118,
      "grad_norm": 51.68904113769531,
      "learning_rate": 1.2700452753030525e-05,
      "loss": 0.2999,
      "step": 3000
    },
    {
      "epoch": 0.415135429426977,
      "grad_norm": 0.8071218729019165,
      "learning_rate": 1.2554403388345261e-05,
      "loss": 0.4169,
      "step": 3050
    },
    {
      "epoch": 0.4219409282700422,
      "grad_norm": 25.48069190979004,
      "learning_rate": 1.2408354023659999e-05,
      "loss": 0.3979,
      "step": 3100
    },
    {
      "epoch": 0.4287464271131074,
      "grad_norm": 21.25867462158203,
      "learning_rate": 1.2262304658974735e-05,
      "loss": 0.2917,
      "step": 3150
    },
    {
      "epoch": 0.4355519259561726,
      "grad_norm": 20.154747009277344,
      "learning_rate": 1.2116255294289471e-05,
      "loss": 0.3333,
      "step": 3200
    },
    {
      "epoch": 0.4423574247992378,
      "grad_norm": 35.4527587890625,
      "learning_rate": 1.1970205929604206e-05,
      "loss": 0.3855,
      "step": 3250
    },
    {
      "epoch": 0.449162923642303,
      "grad_norm": 10.34541130065918,
      "learning_rate": 1.1824156564918943e-05,
      "loss": 0.3828,
      "step": 3300
    },
    {
      "epoch": 0.4559684224853682,
      "grad_norm": 19.207754135131836,
      "learning_rate": 1.167810720023368e-05,
      "loss": 0.3037,
      "step": 3350
    },
    {
      "epoch": 0.46277392132843337,
      "grad_norm": 14.428569793701172,
      "learning_rate": 1.1532057835548415e-05,
      "loss": 0.356,
      "step": 3400
    },
    {
      "epoch": 0.46957942017149856,
      "grad_norm": 0.07625508308410645,
      "learning_rate": 1.1386008470863153e-05,
      "loss": 0.2523,
      "step": 3450
    },
    {
      "epoch": 0.47638491901456376,
      "grad_norm": 44.141502380371094,
      "learning_rate": 1.123995910617789e-05,
      "loss": 0.3763,
      "step": 3500
    },
    {
      "epoch": 0.48319041785762895,
      "grad_norm": 3.85351300239563,
      "learning_rate": 1.1093909741492625e-05,
      "loss": 0.3494,
      "step": 3550
    },
    {
      "epoch": 0.48999591670069415,
      "grad_norm": 37.71319580078125,
      "learning_rate": 1.0947860376807361e-05,
      "loss": 0.3866,
      "step": 3600
    },
    {
      "epoch": 0.49680141554375934,
      "grad_norm": 0.23599348962306976,
      "learning_rate": 1.08018110121221e-05,
      "loss": 0.2894,
      "step": 3650
    },
    {
      "epoch": 0.5036069143868246,
      "grad_norm": 0.2775591015815735,
      "learning_rate": 1.0655761647436835e-05,
      "loss": 0.3734,
      "step": 3700
    },
    {
      "epoch": 0.5104124132298897,
      "grad_norm": 15.113836288452148,
      "learning_rate": 1.0509712282751571e-05,
      "loss": 0.3032,
      "step": 3750
    },
    {
      "epoch": 0.517217912072955,
      "grad_norm": 2.090728521347046,
      "learning_rate": 1.0363662918066306e-05,
      "loss": 0.3239,
      "step": 3800
    },
    {
      "epoch": 0.5240234109160201,
      "grad_norm": 6.337601184844971,
      "learning_rate": 1.0217613553381043e-05,
      "loss": 0.3496,
      "step": 3850
    },
    {
      "epoch": 0.5308289097590854,
      "grad_norm": 58.77766799926758,
      "learning_rate": 1.007156418869578e-05,
      "loss": 0.3563,
      "step": 3900
    },
    {
      "epoch": 0.5376344086021505,
      "grad_norm": 3.2945549488067627,
      "learning_rate": 9.925514824010516e-06,
      "loss": 0.3795,
      "step": 3950
    },
    {
      "epoch": 0.5444399074452158,
      "grad_norm": 14.822299003601074,
      "learning_rate": 9.779465459325253e-06,
      "loss": 0.3109,
      "step": 4000
    },
    {
      "epoch": 0.5512454062882809,
      "grad_norm": 1.6517013311386108,
      "learning_rate": 9.63341609463999e-06,
      "loss": 0.3272,
      "step": 4050
    },
    {
      "epoch": 0.5580509051313461,
      "grad_norm": 0.13707418739795685,
      "learning_rate": 9.487366729954725e-06,
      "loss": 0.2804,
      "step": 4100
    },
    {
      "epoch": 0.5648564039744113,
      "grad_norm": 10.236092567443848,
      "learning_rate": 9.341317365269462e-06,
      "loss": 0.2625,
      "step": 4150
    },
    {
      "epoch": 0.5716619028174765,
      "grad_norm": 3.4045445919036865,
      "learning_rate": 9.195268000584198e-06,
      "loss": 0.336,
      "step": 4200
    },
    {
      "epoch": 0.5784674016605417,
      "grad_norm": 0.20443932712078094,
      "learning_rate": 9.049218635898934e-06,
      "loss": 0.3556,
      "step": 4250
    },
    {
      "epoch": 0.5852729005036069,
      "grad_norm": 2.2975122928619385,
      "learning_rate": 8.903169271213671e-06,
      "loss": 0.4342,
      "step": 4300
    },
    {
      "epoch": 0.5920783993466721,
      "grad_norm": 0.3118405044078827,
      "learning_rate": 8.757119906528408e-06,
      "loss": 0.333,
      "step": 4350
    },
    {
      "epoch": 0.5988838981897373,
      "grad_norm": 0.43903958797454834,
      "learning_rate": 8.611070541843144e-06,
      "loss": 0.3728,
      "step": 4400
    },
    {
      "epoch": 0.6056893970328026,
      "grad_norm": 32.19713592529297,
      "learning_rate": 8.465021177157881e-06,
      "loss": 0.3548,
      "step": 4450
    },
    {
      "epoch": 0.6124948958758677,
      "grad_norm": 23.591552734375,
      "learning_rate": 8.318971812472616e-06,
      "loss": 0.3986,
      "step": 4500
    },
    {
      "epoch": 0.619300394718933,
      "grad_norm": 9.01492977142334,
      "learning_rate": 8.172922447787352e-06,
      "loss": 0.2597,
      "step": 4550
    },
    {
      "epoch": 0.6261058935619981,
      "grad_norm": 6.947440147399902,
      "learning_rate": 8.02687308310209e-06,
      "loss": 0.409,
      "step": 4600
    },
    {
      "epoch": 0.6329113924050633,
      "grad_norm": 43.08353805541992,
      "learning_rate": 7.880823718416826e-06,
      "loss": 0.2527,
      "step": 4650
    },
    {
      "epoch": 0.6397168912481285,
      "grad_norm": 0.634001612663269,
      "learning_rate": 7.734774353731562e-06,
      "loss": 0.3938,
      "step": 4700
    },
    {
      "epoch": 0.6465223900911937,
      "grad_norm": 10.726502418518066,
      "learning_rate": 7.588724989046298e-06,
      "loss": 0.3735,
      "step": 4750
    },
    {
      "epoch": 0.6533278889342589,
      "grad_norm": 10.808802604675293,
      "learning_rate": 7.442675624361035e-06,
      "loss": 0.3438,
      "step": 4800
    },
    {
      "epoch": 0.6601333877773241,
      "grad_norm": 26.112276077270508,
      "learning_rate": 7.296626259675771e-06,
      "loss": 0.4598,
      "step": 4850
    },
    {
      "epoch": 0.6669388866203892,
      "grad_norm": 0.31981584429740906,
      "learning_rate": 7.150576894990508e-06,
      "loss": 0.2513,
      "step": 4900
    },
    {
      "epoch": 0.6737443854634545,
      "grad_norm": 0.17778626084327698,
      "learning_rate": 7.004527530305244e-06,
      "loss": 0.2761,
      "step": 4950
    },
    {
      "epoch": 0.6805498843065196,
      "grad_norm": 25.09307098388672,
      "learning_rate": 6.858478165619981e-06,
      "loss": 0.2494,
      "step": 5000
    },
    {
      "epoch": 0.6873553831495849,
      "grad_norm": 4.4444966316223145,
      "learning_rate": 6.712428800934716e-06,
      "loss": 0.3097,
      "step": 5050
    },
    {
      "epoch": 0.69416088199265,
      "grad_norm": 8.26620101928711,
      "learning_rate": 6.566379436249453e-06,
      "loss": 0.368,
      "step": 5100
    },
    {
      "epoch": 0.7009663808357153,
      "grad_norm": 11.585301399230957,
      "learning_rate": 6.420330071564189e-06,
      "loss": 0.2201,
      "step": 5150
    },
    {
      "epoch": 0.7077718796787804,
      "grad_norm": 24.789169311523438,
      "learning_rate": 6.274280706878926e-06,
      "loss": 0.2774,
      "step": 5200
    },
    {
      "epoch": 0.7145773785218457,
      "grad_norm": 0.1695028394460678,
      "learning_rate": 6.128231342193663e-06,
      "loss": 0.5095,
      "step": 5250
    },
    {
      "epoch": 0.7213828773649108,
      "grad_norm": 1.5706511735916138,
      "learning_rate": 5.982181977508398e-06,
      "loss": 0.294,
      "step": 5300
    },
    {
      "epoch": 0.728188376207976,
      "grad_norm": 27.995750427246094,
      "learning_rate": 5.836132612823134e-06,
      "loss": 0.2696,
      "step": 5350
    },
    {
      "epoch": 0.7349938750510412,
      "grad_norm": 11.418434143066406,
      "learning_rate": 5.690083248137871e-06,
      "loss": 0.2606,
      "step": 5400
    },
    {
      "epoch": 0.7417993738941064,
      "grad_norm": 0.36341479420661926,
      "learning_rate": 5.544033883452608e-06,
      "loss": 0.3172,
      "step": 5450
    },
    {
      "epoch": 0.7486048727371717,
      "grad_norm": 20.357421875,
      "learning_rate": 5.397984518767344e-06,
      "loss": 0.3998,
      "step": 5500
    },
    {
      "epoch": 0.7554103715802368,
      "grad_norm": 49.415767669677734,
      "learning_rate": 5.251935154082081e-06,
      "loss": 0.2988,
      "step": 5550
    },
    {
      "epoch": 0.7622158704233021,
      "grad_norm": 10.44216251373291,
      "learning_rate": 5.105885789396816e-06,
      "loss": 0.2865,
      "step": 5600
    },
    {
      "epoch": 0.7690213692663672,
      "grad_norm": 13.765739440917969,
      "learning_rate": 4.959836424711553e-06,
      "loss": 0.2872,
      "step": 5650
    },
    {
      "epoch": 0.7758268681094325,
      "grad_norm": 51.5184211730957,
      "learning_rate": 4.813787060026289e-06,
      "loss": 0.3449,
      "step": 5700
    },
    {
      "epoch": 0.7826323669524976,
      "grad_norm": 1.7879921197891235,
      "learning_rate": 4.667737695341026e-06,
      "loss": 0.3253,
      "step": 5750
    },
    {
      "epoch": 0.7894378657955629,
      "grad_norm": 2.0926496982574463,
      "learning_rate": 4.521688330655762e-06,
      "loss": 0.2714,
      "step": 5800
    },
    {
      "epoch": 0.796243364638628,
      "grad_norm": 0.14144816994667053,
      "learning_rate": 4.375638965970498e-06,
      "loss": 0.3383,
      "step": 5850
    },
    {
      "epoch": 0.8030488634816932,
      "grad_norm": 0.20430956780910492,
      "learning_rate": 4.229589601285235e-06,
      "loss": 0.4281,
      "step": 5900
    },
    {
      "epoch": 0.8098543623247584,
      "grad_norm": 15.257490158081055,
      "learning_rate": 4.083540236599971e-06,
      "loss": 0.4012,
      "step": 5950
    },
    {
      "epoch": 0.8166598611678236,
      "grad_norm": 20.406789779663086,
      "learning_rate": 3.937490871914708e-06,
      "loss": 0.3297,
      "step": 6000
    },
    {
      "epoch": 0.8234653600108888,
      "grad_norm": 13.500840187072754,
      "learning_rate": 3.7914415072294436e-06,
      "loss": 0.371,
      "step": 6050
    },
    {
      "epoch": 0.830270858853954,
      "grad_norm": 15.123574256896973,
      "learning_rate": 3.64539214254418e-06,
      "loss": 0.2413,
      "step": 6100
    },
    {
      "epoch": 0.8370763576970192,
      "grad_norm": 24.0987606048584,
      "learning_rate": 3.4993427778589166e-06,
      "loss": 0.3218,
      "step": 6150
    },
    {
      "epoch": 0.8438818565400844,
      "grad_norm": 23.050823211669922,
      "learning_rate": 3.3532934131736526e-06,
      "loss": 0.2334,
      "step": 6200
    },
    {
      "epoch": 0.8506873553831495,
      "grad_norm": 0.46464991569519043,
      "learning_rate": 3.207244048488389e-06,
      "loss": 0.3358,
      "step": 6250
    },
    {
      "epoch": 0.8574928542262148,
      "grad_norm": 27.335424423217773,
      "learning_rate": 3.061194683803126e-06,
      "loss": 0.3575,
      "step": 6300
    },
    {
      "epoch": 0.8642983530692799,
      "grad_norm": 25.53172492980957,
      "learning_rate": 2.915145319117862e-06,
      "loss": 0.2606,
      "step": 6350
    },
    {
      "epoch": 0.8711038519123452,
      "grad_norm": 13.31374740600586,
      "learning_rate": 2.7690959544325986e-06,
      "loss": 0.3368,
      "step": 6400
    },
    {
      "epoch": 0.8779093507554103,
      "grad_norm": 1.0185655355453491,
      "learning_rate": 2.623046589747335e-06,
      "loss": 0.2612,
      "step": 6450
    },
    {
      "epoch": 0.8847148495984756,
      "grad_norm": 1.7752487659454346,
      "learning_rate": 2.476997225062071e-06,
      "loss": 0.3176,
      "step": 6500
    },
    {
      "epoch": 0.8915203484415407,
      "grad_norm": 0.20289357006549835,
      "learning_rate": 2.3309478603768077e-06,
      "loss": 0.2694,
      "step": 6550
    },
    {
      "epoch": 0.898325847284606,
      "grad_norm": 0.15803943574428558,
      "learning_rate": 2.184898495691544e-06,
      "loss": 0.3678,
      "step": 6600
    },
    {
      "epoch": 0.9051313461276712,
      "grad_norm": 0.651930570602417,
      "learning_rate": 2.0388491310062802e-06,
      "loss": 0.3068,
      "step": 6650
    },
    {
      "epoch": 0.9119368449707363,
      "grad_norm": 0.3249184787273407,
      "learning_rate": 1.8927997663210165e-06,
      "loss": 0.3269,
      "step": 6700
    },
    {
      "epoch": 0.9187423438138016,
      "grad_norm": 24.370441436767578,
      "learning_rate": 1.7467504016357532e-06,
      "loss": 0.1841,
      "step": 6750
    },
    {
      "epoch": 0.9255478426568667,
      "grad_norm": 45.82298278808594,
      "learning_rate": 1.6007010369504895e-06,
      "loss": 0.3744,
      "step": 6800
    },
    {
      "epoch": 0.932353341499932,
      "grad_norm": 11.94786262512207,
      "learning_rate": 1.4546516722652258e-06,
      "loss": 0.3294,
      "step": 6850
    },
    {
      "epoch": 0.9391588403429971,
      "grad_norm": 0.16881899535655975,
      "learning_rate": 1.3086023075799623e-06,
      "loss": 0.3025,
      "step": 6900
    },
    {
      "epoch": 0.9459643391860624,
      "grad_norm": 0.9113553166389465,
      "learning_rate": 1.1625529428946985e-06,
      "loss": 0.3674,
      "step": 6950
    },
    {
      "epoch": 0.9527698380291275,
      "grad_norm": 0.7720892429351807,
      "learning_rate": 1.0165035782094348e-06,
      "loss": 0.3964,
      "step": 7000
    },
    {
      "epoch": 0.9595753368721928,
      "grad_norm": 30.778175354003906,
      "learning_rate": 8.704542135241713e-07,
      "loss": 0.3557,
      "step": 7050
    },
    {
      "epoch": 0.9663808357152579,
      "grad_norm": 0.22932107746601105,
      "learning_rate": 7.244048488389076e-07,
      "loss": 0.2786,
      "step": 7100
    },
    {
      "epoch": 0.9731863345583232,
      "grad_norm": 0.22739380598068237,
      "learning_rate": 5.78355484153644e-07,
      "loss": 0.3131,
      "step": 7150
    },
    {
      "epoch": 0.9799918334013883,
      "grad_norm": 12.29218864440918,
      "learning_rate": 4.3230611946838036e-07,
      "loss": 0.3412,
      "step": 7200
    },
    {
      "epoch": 0.9867973322444535,
      "grad_norm": 1.365251064300537,
      "learning_rate": 2.862567547831167e-07,
      "loss": 0.3125,
      "step": 7250
    },
    {
      "epoch": 0.9936028310875187,
      "grad_norm": 0.26238587498664856,
      "learning_rate": 1.4020739009785308e-07,
      "loss": 0.3192,
      "step": 7300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9212657366451174,
      "eval_f1": 0.9455862296007148,
      "eval_loss": 0.30750659108161926,
      "eval_runtime": 1712.2524,
      "eval_samples_per_second": 8.582,
      "eval_steps_per_second": 0.269,
      "step": 7347
    }
  ],
  "logging_steps": 50,
  "max_steps": 7347,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3892951911702528.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
