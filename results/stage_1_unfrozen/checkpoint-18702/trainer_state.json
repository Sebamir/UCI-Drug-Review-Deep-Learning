{
  "best_global_step": 18702,
  "best_metric": 0.21287749707698822,
  "best_model_checkpoint": "results\\stage_1_unfrozen\\checkpoint-18702",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 18702,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005347021708908138,
      "grad_norm": 1.378805160522461,
      "learning_rate": 1.9600000000000003e-06,
      "loss": 0.6926,
      "step": 50
    },
    {
      "epoch": 0.010694043417816277,
      "grad_norm": 1.4336763620376587,
      "learning_rate": 3.96e-06,
      "loss": 0.6845,
      "step": 100
    },
    {
      "epoch": 0.016041065126724416,
      "grad_norm": 3.4670872688293457,
      "learning_rate": 5.9600000000000005e-06,
      "loss": 0.6875,
      "step": 150
    },
    {
      "epoch": 0.021388086835632553,
      "grad_norm": 2.028843402862549,
      "learning_rate": 7.960000000000002e-06,
      "loss": 0.6711,
      "step": 200
    },
    {
      "epoch": 0.02673510854454069,
      "grad_norm": 4.351315975189209,
      "learning_rate": 9.960000000000001e-06,
      "loss": 0.6082,
      "step": 250
    },
    {
      "epoch": 0.03208213025344883,
      "grad_norm": 11.395781517028809,
      "learning_rate": 1.196e-05,
      "loss": 0.511,
      "step": 300
    },
    {
      "epoch": 0.037429151962356966,
      "grad_norm": 17.680309295654297,
      "learning_rate": 1.396e-05,
      "loss": 0.4608,
      "step": 350
    },
    {
      "epoch": 0.04277617367126511,
      "grad_norm": 8.01715087890625,
      "learning_rate": 1.5960000000000003e-05,
      "loss": 0.4785,
      "step": 400
    },
    {
      "epoch": 0.04812319538017324,
      "grad_norm": 16.327306747436523,
      "learning_rate": 1.796e-05,
      "loss": 0.4176,
      "step": 450
    },
    {
      "epoch": 0.05347021708908138,
      "grad_norm": 14.848443984985352,
      "learning_rate": 1.9960000000000002e-05,
      "loss": 0.4019,
      "step": 500
    },
    {
      "epoch": 0.05881723879798952,
      "grad_norm": 15.741288185119629,
      "learning_rate": 1.9946159762663445e-05,
      "loss": 0.4618,
      "step": 550
    },
    {
      "epoch": 0.06416426050689766,
      "grad_norm": 1.3692936897277832,
      "learning_rate": 1.9891220744973082e-05,
      "loss": 0.3322,
      "step": 600
    },
    {
      "epoch": 0.0695112822158058,
      "grad_norm": 12.6097412109375,
      "learning_rate": 1.983628172728272e-05,
      "loss": 0.4171,
      "step": 650
    },
    {
      "epoch": 0.07485830392471393,
      "grad_norm": 2.472531318664551,
      "learning_rate": 1.9781342709592356e-05,
      "loss": 0.3694,
      "step": 700
    },
    {
      "epoch": 0.08020532563362208,
      "grad_norm": 12.704851150512695,
      "learning_rate": 1.972640369190199e-05,
      "loss": 0.405,
      "step": 750
    },
    {
      "epoch": 0.08555234734253021,
      "grad_norm": 30.13095474243164,
      "learning_rate": 1.9671464674211627e-05,
      "loss": 0.3766,
      "step": 800
    },
    {
      "epoch": 0.09089936905143835,
      "grad_norm": 2.8249127864837646,
      "learning_rate": 1.9616525656521264e-05,
      "loss": 0.3855,
      "step": 850
    },
    {
      "epoch": 0.09624639076034648,
      "grad_norm": 3.663248062133789,
      "learning_rate": 1.9561586638830898e-05,
      "loss": 0.4228,
      "step": 900
    },
    {
      "epoch": 0.10159341246925463,
      "grad_norm": 1.1196235418319702,
      "learning_rate": 1.9506647621140535e-05,
      "loss": 0.3765,
      "step": 950
    },
    {
      "epoch": 0.10694043417816276,
      "grad_norm": 13.400036811828613,
      "learning_rate": 1.9451708603450172e-05,
      "loss": 0.3395,
      "step": 1000
    },
    {
      "epoch": 0.1122874558870709,
      "grad_norm": 6.569674491882324,
      "learning_rate": 1.939676958575981e-05,
      "loss": 0.4211,
      "step": 1050
    },
    {
      "epoch": 0.11763447759597905,
      "grad_norm": 2.7657294273376465,
      "learning_rate": 1.9341830568069443e-05,
      "loss": 0.3425,
      "step": 1100
    },
    {
      "epoch": 0.12298149930488718,
      "grad_norm": 7.33969259262085,
      "learning_rate": 1.928689155037908e-05,
      "loss": 0.3805,
      "step": 1150
    },
    {
      "epoch": 0.12832852101379533,
      "grad_norm": 0.8315293788909912,
      "learning_rate": 1.9231952532688717e-05,
      "loss": 0.3115,
      "step": 1200
    },
    {
      "epoch": 0.13367554272270346,
      "grad_norm": 16.877418518066406,
      "learning_rate": 1.917701351499835e-05,
      "loss": 0.3408,
      "step": 1250
    },
    {
      "epoch": 0.1390225644316116,
      "grad_norm": 14.575719833374023,
      "learning_rate": 1.912207449730799e-05,
      "loss": 0.4091,
      "step": 1300
    },
    {
      "epoch": 0.14436958614051973,
      "grad_norm": 10.32137680053711,
      "learning_rate": 1.9067135479617626e-05,
      "loss": 0.4213,
      "step": 1350
    },
    {
      "epoch": 0.14971660784942786,
      "grad_norm": 14.646960258483887,
      "learning_rate": 1.9012196461927263e-05,
      "loss": 0.3606,
      "step": 1400
    },
    {
      "epoch": 0.155063629558336,
      "grad_norm": 5.434014797210693,
      "learning_rate": 1.89572574442369e-05,
      "loss": 0.3533,
      "step": 1450
    },
    {
      "epoch": 0.16041065126724416,
      "grad_norm": 2.0011775493621826,
      "learning_rate": 1.8902318426546537e-05,
      "loss": 0.3239,
      "step": 1500
    },
    {
      "epoch": 0.1657576729761523,
      "grad_norm": 11.753279685974121,
      "learning_rate": 1.884737940885617e-05,
      "loss": 0.2946,
      "step": 1550
    },
    {
      "epoch": 0.17110469468506043,
      "grad_norm": 8.398914337158203,
      "learning_rate": 1.8792440391165808e-05,
      "loss": 0.3872,
      "step": 1600
    },
    {
      "epoch": 0.17645171639396856,
      "grad_norm": 12.33010482788086,
      "learning_rate": 1.8737501373475445e-05,
      "loss": 0.361,
      "step": 1650
    },
    {
      "epoch": 0.1817987381028767,
      "grad_norm": 12.254762649536133,
      "learning_rate": 1.8682562355785082e-05,
      "loss": 0.3533,
      "step": 1700
    },
    {
      "epoch": 0.18714575981178483,
      "grad_norm": 2.0727243423461914,
      "learning_rate": 1.8627623338094716e-05,
      "loss": 0.2926,
      "step": 1750
    },
    {
      "epoch": 0.19249278152069296,
      "grad_norm": 1.6039931774139404,
      "learning_rate": 1.8572684320404353e-05,
      "loss": 0.3356,
      "step": 1800
    },
    {
      "epoch": 0.19783980322960112,
      "grad_norm": 19.080467224121094,
      "learning_rate": 1.851774530271399e-05,
      "loss": 0.3619,
      "step": 1850
    },
    {
      "epoch": 0.20318682493850926,
      "grad_norm": 3.3939690589904785,
      "learning_rate": 1.8462806285023624e-05,
      "loss": 0.3285,
      "step": 1900
    },
    {
      "epoch": 0.2085338466474174,
      "grad_norm": 3.7839245796203613,
      "learning_rate": 1.840786726733326e-05,
      "loss": 0.296,
      "step": 1950
    },
    {
      "epoch": 0.21388086835632553,
      "grad_norm": 9.542397499084473,
      "learning_rate": 1.83529282496429e-05,
      "loss": 0.3228,
      "step": 2000
    },
    {
      "epoch": 0.21922789006523366,
      "grad_norm": 11.032031059265137,
      "learning_rate": 1.8297989231952532e-05,
      "loss": 0.3419,
      "step": 2050
    },
    {
      "epoch": 0.2245749117741418,
      "grad_norm": 17.0900936126709,
      "learning_rate": 1.824305021426217e-05,
      "loss": 0.3144,
      "step": 2100
    },
    {
      "epoch": 0.22992193348304993,
      "grad_norm": 8.812235832214355,
      "learning_rate": 1.8188111196571806e-05,
      "loss": 0.3789,
      "step": 2150
    },
    {
      "epoch": 0.2352689551919581,
      "grad_norm": 8.220836639404297,
      "learning_rate": 1.8133172178881444e-05,
      "loss": 0.319,
      "step": 2200
    },
    {
      "epoch": 0.24061597690086622,
      "grad_norm": 16.62322998046875,
      "learning_rate": 1.8078233161191077e-05,
      "loss": 0.323,
      "step": 2250
    },
    {
      "epoch": 0.24596299860977436,
      "grad_norm": 18.836570739746094,
      "learning_rate": 1.8023294143500715e-05,
      "loss": 0.3296,
      "step": 2300
    },
    {
      "epoch": 0.2513100203186825,
      "grad_norm": 16.95131492614746,
      "learning_rate": 1.7968355125810352e-05,
      "loss": 0.3311,
      "step": 2350
    },
    {
      "epoch": 0.25665704202759065,
      "grad_norm": 1.14356529712677,
      "learning_rate": 1.791341610811999e-05,
      "loss": 0.2435,
      "step": 2400
    },
    {
      "epoch": 0.26200406373649876,
      "grad_norm": 20.487897872924805,
      "learning_rate": 1.7858477090429626e-05,
      "loss": 0.306,
      "step": 2450
    },
    {
      "epoch": 0.2673510854454069,
      "grad_norm": 6.587573528289795,
      "learning_rate": 1.7803538072739263e-05,
      "loss": 0.3755,
      "step": 2500
    },
    {
      "epoch": 0.27269810715431503,
      "grad_norm": 34.0817985534668,
      "learning_rate": 1.7748599055048897e-05,
      "loss": 0.3277,
      "step": 2550
    },
    {
      "epoch": 0.2780451288632232,
      "grad_norm": 10.669944763183594,
      "learning_rate": 1.7693660037358534e-05,
      "loss": 0.3598,
      "step": 2600
    },
    {
      "epoch": 0.2833921505721313,
      "grad_norm": 7.044344425201416,
      "learning_rate": 1.763872101966817e-05,
      "loss": 0.3462,
      "step": 2650
    },
    {
      "epoch": 0.28873917228103946,
      "grad_norm": 16.4897518157959,
      "learning_rate": 1.758378200197781e-05,
      "loss": 0.3317,
      "step": 2700
    },
    {
      "epoch": 0.2940861939899476,
      "grad_norm": 6.035110950469971,
      "learning_rate": 1.7528842984287442e-05,
      "loss": 0.3511,
      "step": 2750
    },
    {
      "epoch": 0.2994332156988557,
      "grad_norm": 10.592534065246582,
      "learning_rate": 1.747390396659708e-05,
      "loss": 0.3208,
      "step": 2800
    },
    {
      "epoch": 0.3047802374077639,
      "grad_norm": 8.10433292388916,
      "learning_rate": 1.7418964948906716e-05,
      "loss": 0.3163,
      "step": 2850
    },
    {
      "epoch": 0.310127259116672,
      "grad_norm": 0.432722806930542,
      "learning_rate": 1.736402593121635e-05,
      "loss": 0.3267,
      "step": 2900
    },
    {
      "epoch": 0.31547428082558016,
      "grad_norm": 3.630265951156616,
      "learning_rate": 1.7309086913525987e-05,
      "loss": 0.3536,
      "step": 2950
    },
    {
      "epoch": 0.3208213025344883,
      "grad_norm": 29.886791229248047,
      "learning_rate": 1.7254147895835625e-05,
      "loss": 0.2491,
      "step": 3000
    },
    {
      "epoch": 0.3261683242433964,
      "grad_norm": 17.40411376953125,
      "learning_rate": 1.719920887814526e-05,
      "loss": 0.2787,
      "step": 3050
    },
    {
      "epoch": 0.3315153459523046,
      "grad_norm": 9.210959434509277,
      "learning_rate": 1.7144269860454895e-05,
      "loss": 0.3658,
      "step": 3100
    },
    {
      "epoch": 0.3368623676612127,
      "grad_norm": 19.992637634277344,
      "learning_rate": 1.7089330842764533e-05,
      "loss": 0.3617,
      "step": 3150
    },
    {
      "epoch": 0.34220938937012085,
      "grad_norm": 13.792549133300781,
      "learning_rate": 1.7034391825074166e-05,
      "loss": 0.2504,
      "step": 3200
    },
    {
      "epoch": 0.34755641107902896,
      "grad_norm": 16.035053253173828,
      "learning_rate": 1.6979452807383804e-05,
      "loss": 0.349,
      "step": 3250
    },
    {
      "epoch": 0.3529034327879371,
      "grad_norm": 0.7599762082099915,
      "learning_rate": 1.692451378969344e-05,
      "loss": 0.2812,
      "step": 3300
    },
    {
      "epoch": 0.3582504544968453,
      "grad_norm": 5.658361911773682,
      "learning_rate": 1.6869574772003078e-05,
      "loss": 0.2837,
      "step": 3350
    },
    {
      "epoch": 0.3635974762057534,
      "grad_norm": 11.032227516174316,
      "learning_rate": 1.6814635754312715e-05,
      "loss": 0.2803,
      "step": 3400
    },
    {
      "epoch": 0.36894449791466155,
      "grad_norm": 0.6362072825431824,
      "learning_rate": 1.6759696736622352e-05,
      "loss": 0.3305,
      "step": 3450
    },
    {
      "epoch": 0.37429151962356966,
      "grad_norm": 21.52455711364746,
      "learning_rate": 1.6704757718931986e-05,
      "loss": 0.2982,
      "step": 3500
    },
    {
      "epoch": 0.3796385413324778,
      "grad_norm": 1.0980523824691772,
      "learning_rate": 1.6649818701241623e-05,
      "loss": 0.3791,
      "step": 3550
    },
    {
      "epoch": 0.3849855630413859,
      "grad_norm": 8.063138961791992,
      "learning_rate": 1.659487968355126e-05,
      "loss": 0.3365,
      "step": 3600
    },
    {
      "epoch": 0.3903325847502941,
      "grad_norm": 4.476261138916016,
      "learning_rate": 1.6539940665860897e-05,
      "loss": 0.3162,
      "step": 3650
    },
    {
      "epoch": 0.39567960645920225,
      "grad_norm": 3.405261516571045,
      "learning_rate": 1.648500164817053e-05,
      "loss": 0.3437,
      "step": 3700
    },
    {
      "epoch": 0.40102662816811036,
      "grad_norm": 28.007524490356445,
      "learning_rate": 1.643006263048017e-05,
      "loss": 0.2625,
      "step": 3750
    },
    {
      "epoch": 0.4063736498770185,
      "grad_norm": 29.552804946899414,
      "learning_rate": 1.6375123612789806e-05,
      "loss": 0.2767,
      "step": 3800
    },
    {
      "epoch": 0.4117206715859266,
      "grad_norm": 8.315073013305664,
      "learning_rate": 1.6320184595099443e-05,
      "loss": 0.3488,
      "step": 3850
    },
    {
      "epoch": 0.4170676932948348,
      "grad_norm": 7.427602767944336,
      "learning_rate": 1.6265245577409076e-05,
      "loss": 0.2658,
      "step": 3900
    },
    {
      "epoch": 0.4224147150037429,
      "grad_norm": 11.256396293640137,
      "learning_rate": 1.6210306559718714e-05,
      "loss": 0.2853,
      "step": 3950
    },
    {
      "epoch": 0.42776173671265105,
      "grad_norm": 0.9796546697616577,
      "learning_rate": 1.615536754202835e-05,
      "loss": 0.3146,
      "step": 4000
    },
    {
      "epoch": 0.4331087584215592,
      "grad_norm": 1.437658667564392,
      "learning_rate": 1.6100428524337985e-05,
      "loss": 0.3722,
      "step": 4050
    },
    {
      "epoch": 0.4384557801304673,
      "grad_norm": 20.798364639282227,
      "learning_rate": 1.604548950664762e-05,
      "loss": 0.3447,
      "step": 4100
    },
    {
      "epoch": 0.4438028018393755,
      "grad_norm": 6.490728855133057,
      "learning_rate": 1.599055048895726e-05,
      "loss": 0.2549,
      "step": 4150
    },
    {
      "epoch": 0.4491498235482836,
      "grad_norm": 1.8283354043960571,
      "learning_rate": 1.5935611471266893e-05,
      "loss": 0.27,
      "step": 4200
    },
    {
      "epoch": 0.45449684525719175,
      "grad_norm": 6.500503063201904,
      "learning_rate": 1.588067245357653e-05,
      "loss": 0.2917,
      "step": 4250
    },
    {
      "epoch": 0.45984386696609986,
      "grad_norm": 2.4171767234802246,
      "learning_rate": 1.5825733435886167e-05,
      "loss": 0.2985,
      "step": 4300
    },
    {
      "epoch": 0.465190888675008,
      "grad_norm": 24.638322830200195,
      "learning_rate": 1.5770794418195804e-05,
      "loss": 0.2612,
      "step": 4350
    },
    {
      "epoch": 0.4705379103839162,
      "grad_norm": 8.932291984558105,
      "learning_rate": 1.571585540050544e-05,
      "loss": 0.398,
      "step": 4400
    },
    {
      "epoch": 0.4758849320928243,
      "grad_norm": 0.2542301118373871,
      "learning_rate": 1.566091638281508e-05,
      "loss": 0.2563,
      "step": 4450
    },
    {
      "epoch": 0.48123195380173245,
      "grad_norm": 1.436380386352539,
      "learning_rate": 1.5605977365124712e-05,
      "loss": 0.3337,
      "step": 4500
    },
    {
      "epoch": 0.48657897551064055,
      "grad_norm": 17.177778244018555,
      "learning_rate": 1.555103834743435e-05,
      "loss": 0.2824,
      "step": 4550
    },
    {
      "epoch": 0.4919259972195487,
      "grad_norm": 13.856968879699707,
      "learning_rate": 1.5496099329743986e-05,
      "loss": 0.2615,
      "step": 4600
    },
    {
      "epoch": 0.4972730189284568,
      "grad_norm": 0.3829154670238495,
      "learning_rate": 1.5441160312053624e-05,
      "loss": 0.2903,
      "step": 4650
    },
    {
      "epoch": 0.502620040637365,
      "grad_norm": 13.67843246459961,
      "learning_rate": 1.5386221294363257e-05,
      "loss": 0.3565,
      "step": 4700
    },
    {
      "epoch": 0.5079670623462731,
      "grad_norm": 7.976902961730957,
      "learning_rate": 1.5331282276672895e-05,
      "loss": 0.2293,
      "step": 4750
    },
    {
      "epoch": 0.5133140840551813,
      "grad_norm": 33.500099182128906,
      "learning_rate": 1.5276343258982532e-05,
      "loss": 0.2552,
      "step": 4800
    },
    {
      "epoch": 0.5186611057640894,
      "grad_norm": 29.769241333007812,
      "learning_rate": 1.5221404241292165e-05,
      "loss": 0.2855,
      "step": 4850
    },
    {
      "epoch": 0.5240081274729975,
      "grad_norm": 32.992671966552734,
      "learning_rate": 1.5166465223601803e-05,
      "loss": 0.2767,
      "step": 4900
    },
    {
      "epoch": 0.5293551491819056,
      "grad_norm": 5.020203113555908,
      "learning_rate": 1.511152620591144e-05,
      "loss": 0.2636,
      "step": 4950
    },
    {
      "epoch": 0.5347021708908138,
      "grad_norm": 4.678391933441162,
      "learning_rate": 1.5056587188221077e-05,
      "loss": 0.3073,
      "step": 5000
    },
    {
      "epoch": 0.540049192599722,
      "grad_norm": 18.76891326904297,
      "learning_rate": 1.500164817053071e-05,
      "loss": 0.2963,
      "step": 5050
    },
    {
      "epoch": 0.5453962143086301,
      "grad_norm": 33.79658126831055,
      "learning_rate": 1.4946709152840348e-05,
      "loss": 0.2597,
      "step": 5100
    },
    {
      "epoch": 0.5507432360175383,
      "grad_norm": 13.764065742492676,
      "learning_rate": 1.4891770135149985e-05,
      "loss": 0.3153,
      "step": 5150
    },
    {
      "epoch": 0.5560902577264464,
      "grad_norm": 1.0889666080474854,
      "learning_rate": 1.483683111745962e-05,
      "loss": 0.3012,
      "step": 5200
    },
    {
      "epoch": 0.5614372794353545,
      "grad_norm": 9.479805946350098,
      "learning_rate": 1.4781892099769258e-05,
      "loss": 0.3287,
      "step": 5250
    },
    {
      "epoch": 0.5667843011442626,
      "grad_norm": 2.6477463245391846,
      "learning_rate": 1.4726953082078895e-05,
      "loss": 0.2603,
      "step": 5300
    },
    {
      "epoch": 0.5721313228531708,
      "grad_norm": 7.694854736328125,
      "learning_rate": 1.4672014064388529e-05,
      "loss": 0.315,
      "step": 5350
    },
    {
      "epoch": 0.5774783445620789,
      "grad_norm": 17.506803512573242,
      "learning_rate": 1.4617075046698166e-05,
      "loss": 0.3297,
      "step": 5400
    },
    {
      "epoch": 0.582825366270987,
      "grad_norm": 12.999232292175293,
      "learning_rate": 1.4562136029007803e-05,
      "loss": 0.2736,
      "step": 5450
    },
    {
      "epoch": 0.5881723879798952,
      "grad_norm": 0.2751125991344452,
      "learning_rate": 1.450719701131744e-05,
      "loss": 0.3102,
      "step": 5500
    },
    {
      "epoch": 0.5935194096888033,
      "grad_norm": 6.569575786590576,
      "learning_rate": 1.4452257993627074e-05,
      "loss": 0.2638,
      "step": 5550
    },
    {
      "epoch": 0.5988664313977115,
      "grad_norm": 32.77351379394531,
      "learning_rate": 1.4397318975936711e-05,
      "loss": 0.3187,
      "step": 5600
    },
    {
      "epoch": 0.6042134531066196,
      "grad_norm": 23.572668075561523,
      "learning_rate": 1.4342379958246348e-05,
      "loss": 0.2158,
      "step": 5650
    },
    {
      "epoch": 0.6095604748155278,
      "grad_norm": 7.257338047027588,
      "learning_rate": 1.4287440940555984e-05,
      "loss": 0.3173,
      "step": 5700
    },
    {
      "epoch": 0.6149074965244359,
      "grad_norm": 4.207103729248047,
      "learning_rate": 1.423250192286562e-05,
      "loss": 0.2668,
      "step": 5750
    },
    {
      "epoch": 0.620254518233344,
      "grad_norm": 14.392342567443848,
      "learning_rate": 1.4177562905175258e-05,
      "loss": 0.2998,
      "step": 5800
    },
    {
      "epoch": 0.6256015399422522,
      "grad_norm": 14.726716995239258,
      "learning_rate": 1.4122623887484892e-05,
      "loss": 0.298,
      "step": 5850
    },
    {
      "epoch": 0.6309485616511603,
      "grad_norm": 53.96920394897461,
      "learning_rate": 1.4067684869794529e-05,
      "loss": 0.2913,
      "step": 5900
    },
    {
      "epoch": 0.6362955833600684,
      "grad_norm": 6.4491658210754395,
      "learning_rate": 1.4012745852104166e-05,
      "loss": 0.2828,
      "step": 5950
    },
    {
      "epoch": 0.6416426050689766,
      "grad_norm": 6.312446594238281,
      "learning_rate": 1.3957806834413803e-05,
      "loss": 0.2588,
      "step": 6000
    },
    {
      "epoch": 0.6469896267778847,
      "grad_norm": 0.16081200540065765,
      "learning_rate": 1.3902867816723437e-05,
      "loss": 0.2264,
      "step": 6050
    },
    {
      "epoch": 0.6523366484867928,
      "grad_norm": 14.364632606506348,
      "learning_rate": 1.3847928799033074e-05,
      "loss": 0.2887,
      "step": 6100
    },
    {
      "epoch": 0.657683670195701,
      "grad_norm": 28.246402740478516,
      "learning_rate": 1.3792989781342711e-05,
      "loss": 0.3337,
      "step": 6150
    },
    {
      "epoch": 0.6630306919046092,
      "grad_norm": 35.95964813232422,
      "learning_rate": 1.3738050763652347e-05,
      "loss": 0.264,
      "step": 6200
    },
    {
      "epoch": 0.6683777136135173,
      "grad_norm": 0.8535335659980774,
      "learning_rate": 1.3683111745961984e-05,
      "loss": 0.3094,
      "step": 6250
    },
    {
      "epoch": 0.6737247353224254,
      "grad_norm": 0.6089958548545837,
      "learning_rate": 1.3628172728271621e-05,
      "loss": 0.2404,
      "step": 6300
    },
    {
      "epoch": 0.6790717570313336,
      "grad_norm": 10.035326957702637,
      "learning_rate": 1.3573233710581255e-05,
      "loss": 0.2482,
      "step": 6350
    },
    {
      "epoch": 0.6844187787402417,
      "grad_norm": 0.1748385727405548,
      "learning_rate": 1.3518294692890892e-05,
      "loss": 0.2469,
      "step": 6400
    },
    {
      "epoch": 0.6897658004491498,
      "grad_norm": 2.555701494216919,
      "learning_rate": 1.3463355675200529e-05,
      "loss": 0.3264,
      "step": 6450
    },
    {
      "epoch": 0.6951128221580579,
      "grad_norm": 3.191561222076416,
      "learning_rate": 1.3408416657510165e-05,
      "loss": 0.2879,
      "step": 6500
    },
    {
      "epoch": 0.7004598438669661,
      "grad_norm": 0.18540339171886444,
      "learning_rate": 1.33534776398198e-05,
      "loss": 0.2912,
      "step": 6550
    },
    {
      "epoch": 0.7058068655758742,
      "grad_norm": 15.401322364807129,
      "learning_rate": 1.3298538622129437e-05,
      "loss": 0.3142,
      "step": 6600
    },
    {
      "epoch": 0.7111538872847823,
      "grad_norm": 0.38978907465934753,
      "learning_rate": 1.3243599604439074e-05,
      "loss": 0.2514,
      "step": 6650
    },
    {
      "epoch": 0.7165009089936906,
      "grad_norm": 18.929290771484375,
      "learning_rate": 1.318866058674871e-05,
      "loss": 0.258,
      "step": 6700
    },
    {
      "epoch": 0.7218479307025987,
      "grad_norm": 2.1079561710357666,
      "learning_rate": 1.3133721569058347e-05,
      "loss": 0.3163,
      "step": 6750
    },
    {
      "epoch": 0.7271949524115068,
      "grad_norm": 0.7695014476776123,
      "learning_rate": 1.3078782551367984e-05,
      "loss": 0.2415,
      "step": 6800
    },
    {
      "epoch": 0.7325419741204149,
      "grad_norm": 0.27859634160995483,
      "learning_rate": 1.3023843533677618e-05,
      "loss": 0.2776,
      "step": 6850
    },
    {
      "epoch": 0.7378889958293231,
      "grad_norm": 40.21552658081055,
      "learning_rate": 1.2968904515987255e-05,
      "loss": 0.2457,
      "step": 6900
    },
    {
      "epoch": 0.7432360175382312,
      "grad_norm": 14.42630386352539,
      "learning_rate": 1.2913965498296892e-05,
      "loss": 0.2492,
      "step": 6950
    },
    {
      "epoch": 0.7485830392471393,
      "grad_norm": 0.38756653666496277,
      "learning_rate": 1.2859026480606528e-05,
      "loss": 0.3358,
      "step": 7000
    },
    {
      "epoch": 0.7539300609560475,
      "grad_norm": 12.004216194152832,
      "learning_rate": 1.2804087462916163e-05,
      "loss": 0.2471,
      "step": 7050
    },
    {
      "epoch": 0.7592770826649556,
      "grad_norm": 1.8490909337997437,
      "learning_rate": 1.27491484452258e-05,
      "loss": 0.2879,
      "step": 7100
    },
    {
      "epoch": 0.7646241043738637,
      "grad_norm": 10.53575325012207,
      "learning_rate": 1.2694209427535437e-05,
      "loss": 0.2866,
      "step": 7150
    },
    {
      "epoch": 0.7699711260827719,
      "grad_norm": 8.593047142028809,
      "learning_rate": 1.2639270409845073e-05,
      "loss": 0.2343,
      "step": 7200
    },
    {
      "epoch": 0.7753181477916801,
      "grad_norm": 0.4566565752029419,
      "learning_rate": 1.258433139215471e-05,
      "loss": 0.2337,
      "step": 7250
    },
    {
      "epoch": 0.7806651695005882,
      "grad_norm": 24.75602149963379,
      "learning_rate": 1.2529392374464347e-05,
      "loss": 0.3111,
      "step": 7300
    },
    {
      "epoch": 0.7860121912094963,
      "grad_norm": 6.254673480987549,
      "learning_rate": 1.2474453356773981e-05,
      "loss": 0.2926,
      "step": 7350
    },
    {
      "epoch": 0.7913592129184045,
      "grad_norm": 15.585022926330566,
      "learning_rate": 1.2419514339083618e-05,
      "loss": 0.2769,
      "step": 7400
    },
    {
      "epoch": 0.7967062346273126,
      "grad_norm": 19.897245407104492,
      "learning_rate": 1.2364575321393255e-05,
      "loss": 0.2174,
      "step": 7450
    },
    {
      "epoch": 0.8020532563362207,
      "grad_norm": 13.387712478637695,
      "learning_rate": 1.2309636303702889e-05,
      "loss": 0.2375,
      "step": 7500
    },
    {
      "epoch": 0.8074002780451288,
      "grad_norm": 0.45848706364631653,
      "learning_rate": 1.2254697286012526e-05,
      "loss": 0.3134,
      "step": 7550
    },
    {
      "epoch": 0.812747299754037,
      "grad_norm": 3.112612247467041,
      "learning_rate": 1.2199758268322163e-05,
      "loss": 0.2163,
      "step": 7600
    },
    {
      "epoch": 0.8180943214629451,
      "grad_norm": 0.902765691280365,
      "learning_rate": 1.21448192506318e-05,
      "loss": 0.3259,
      "step": 7650
    },
    {
      "epoch": 0.8234413431718532,
      "grad_norm": 0.7532958984375,
      "learning_rate": 1.2089880232941436e-05,
      "loss": 0.2751,
      "step": 7700
    },
    {
      "epoch": 0.8287883648807615,
      "grad_norm": 12.222504615783691,
      "learning_rate": 1.2034941215251073e-05,
      "loss": 0.2413,
      "step": 7750
    },
    {
      "epoch": 0.8341353865896696,
      "grad_norm": 28.999284744262695,
      "learning_rate": 1.198000219756071e-05,
      "loss": 0.2631,
      "step": 7800
    },
    {
      "epoch": 0.8394824082985777,
      "grad_norm": 35.8948860168457,
      "learning_rate": 1.1925063179870344e-05,
      "loss": 0.2692,
      "step": 7850
    },
    {
      "epoch": 0.8448294300074858,
      "grad_norm": 57.96863555908203,
      "learning_rate": 1.1870124162179981e-05,
      "loss": 0.2837,
      "step": 7900
    },
    {
      "epoch": 0.850176451716394,
      "grad_norm": 13.253071784973145,
      "learning_rate": 1.1815185144489618e-05,
      "loss": 0.2741,
      "step": 7950
    },
    {
      "epoch": 0.8555234734253021,
      "grad_norm": 4.508538246154785,
      "learning_rate": 1.1760246126799252e-05,
      "loss": 0.2486,
      "step": 8000
    },
    {
      "epoch": 0.8608704951342102,
      "grad_norm": 9.999918937683105,
      "learning_rate": 1.170530710910889e-05,
      "loss": 0.2083,
      "step": 8050
    },
    {
      "epoch": 0.8662175168431184,
      "grad_norm": 17.0297794342041,
      "learning_rate": 1.1650368091418526e-05,
      "loss": 0.2295,
      "step": 8100
    },
    {
      "epoch": 0.8715645385520265,
      "grad_norm": 39.144248962402344,
      "learning_rate": 1.1595429073728162e-05,
      "loss": 0.2475,
      "step": 8150
    },
    {
      "epoch": 0.8769115602609346,
      "grad_norm": 25.9428653717041,
      "learning_rate": 1.1540490056037799e-05,
      "loss": 0.2365,
      "step": 8200
    },
    {
      "epoch": 0.8822585819698427,
      "grad_norm": 40.980491638183594,
      "learning_rate": 1.1485551038347436e-05,
      "loss": 0.2837,
      "step": 8250
    },
    {
      "epoch": 0.887605603678751,
      "grad_norm": 13.998931884765625,
      "learning_rate": 1.1430612020657073e-05,
      "loss": 0.2676,
      "step": 8300
    },
    {
      "epoch": 0.8929526253876591,
      "grad_norm": 7.160714626312256,
      "learning_rate": 1.1375673002966707e-05,
      "loss": 0.2168,
      "step": 8350
    },
    {
      "epoch": 0.8982996470965672,
      "grad_norm": 14.453361511230469,
      "learning_rate": 1.1320733985276344e-05,
      "loss": 0.3017,
      "step": 8400
    },
    {
      "epoch": 0.9036466688054754,
      "grad_norm": 0.9022241830825806,
      "learning_rate": 1.1265794967585981e-05,
      "loss": 0.2132,
      "step": 8450
    },
    {
      "epoch": 0.9089936905143835,
      "grad_norm": 21.806177139282227,
      "learning_rate": 1.1210855949895615e-05,
      "loss": 0.2017,
      "step": 8500
    },
    {
      "epoch": 0.9143407122232916,
      "grad_norm": 23.016714096069336,
      "learning_rate": 1.1155916932205252e-05,
      "loss": 0.2813,
      "step": 8550
    },
    {
      "epoch": 0.9196877339321997,
      "grad_norm": 3.0114128589630127,
      "learning_rate": 1.110097791451489e-05,
      "loss": 0.2832,
      "step": 8600
    },
    {
      "epoch": 0.9250347556411079,
      "grad_norm": 0.20032203197479248,
      "learning_rate": 1.1046038896824525e-05,
      "loss": 0.2275,
      "step": 8650
    },
    {
      "epoch": 0.930381777350016,
      "grad_norm": 34.2493896484375,
      "learning_rate": 1.0991099879134162e-05,
      "loss": 0.2137,
      "step": 8700
    },
    {
      "epoch": 0.9357287990589241,
      "grad_norm": 30.6427059173584,
      "learning_rate": 1.09361608614438e-05,
      "loss": 0.2523,
      "step": 8750
    },
    {
      "epoch": 0.9410758207678324,
      "grad_norm": 0.33596739172935486,
      "learning_rate": 1.0881221843753435e-05,
      "loss": 0.226,
      "step": 8800
    },
    {
      "epoch": 0.9464228424767405,
      "grad_norm": 24.635095596313477,
      "learning_rate": 1.082628282606307e-05,
      "loss": 0.263,
      "step": 8850
    },
    {
      "epoch": 0.9517698641856486,
      "grad_norm": 0.4012242555618286,
      "learning_rate": 1.0771343808372707e-05,
      "loss": 0.2835,
      "step": 8900
    },
    {
      "epoch": 0.9571168858945567,
      "grad_norm": 7.348691463470459,
      "learning_rate": 1.0716404790682345e-05,
      "loss": 0.2584,
      "step": 8950
    },
    {
      "epoch": 0.9624639076034649,
      "grad_norm": 2.6937384605407715,
      "learning_rate": 1.0661465772991978e-05,
      "loss": 0.2502,
      "step": 9000
    },
    {
      "epoch": 0.967810929312373,
      "grad_norm": 19.654991149902344,
      "learning_rate": 1.0606526755301615e-05,
      "loss": 0.2579,
      "step": 9050
    },
    {
      "epoch": 0.9731579510212811,
      "grad_norm": 4.129249095916748,
      "learning_rate": 1.0551587737611253e-05,
      "loss": 0.2639,
      "step": 9100
    },
    {
      "epoch": 0.9785049727301893,
      "grad_norm": 0.20282022655010223,
      "learning_rate": 1.0496648719920888e-05,
      "loss": 0.2372,
      "step": 9150
    },
    {
      "epoch": 0.9838519944390974,
      "grad_norm": 3.9283649921417236,
      "learning_rate": 1.0441709702230525e-05,
      "loss": 0.3096,
      "step": 9200
    },
    {
      "epoch": 0.9891990161480055,
      "grad_norm": 1.3598666191101074,
      "learning_rate": 1.0386770684540162e-05,
      "loss": 0.298,
      "step": 9250
    },
    {
      "epoch": 0.9945460378569136,
      "grad_norm": 28.32166862487793,
      "learning_rate": 1.0331831666849798e-05,
      "loss": 0.2407,
      "step": 9300
    },
    {
      "epoch": 0.9998930595658219,
      "grad_norm": 0.7888848781585693,
      "learning_rate": 1.0276892649159433e-05,
      "loss": 0.2429,
      "step": 9350
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9325740562506684,
      "eval_f1": 0.9410224030681447,
      "eval_loss": 0.21732069551944733,
      "eval_precision": 0.9407144193005423,
      "eval_recall": 0.941330588565547,
      "eval_runtime": 1852.0374,
      "eval_samples_per_second": 10.098,
      "eval_steps_per_second": 0.316,
      "step": 9351
    },
    {
      "epoch": 1.00524008127473,
      "grad_norm": 8.122475624084473,
      "learning_rate": 1.022195363146907e-05,
      "loss": 0.1938,
      "step": 9400
    },
    {
      "epoch": 1.0105871029836382,
      "grad_norm": 0.05538545548915863,
      "learning_rate": 1.0167014613778708e-05,
      "loss": 0.1886,
      "step": 9450
    },
    {
      "epoch": 1.0159341246925462,
      "grad_norm": 0.09572991728782654,
      "learning_rate": 1.0112075596088341e-05,
      "loss": 0.1441,
      "step": 9500
    },
    {
      "epoch": 1.0212811464014544,
      "grad_norm": 0.48448446393013,
      "learning_rate": 1.0057136578397979e-05,
      "loss": 0.2165,
      "step": 9550
    },
    {
      "epoch": 1.0266281681103626,
      "grad_norm": 0.12586921453475952,
      "learning_rate": 1.0002197560707616e-05,
      "loss": 0.14,
      "step": 9600
    },
    {
      "epoch": 1.0319751898192706,
      "grad_norm": 46.96935272216797,
      "learning_rate": 9.947258543017251e-06,
      "loss": 0.1785,
      "step": 9650
    },
    {
      "epoch": 1.0373222115281788,
      "grad_norm": 16.425748825073242,
      "learning_rate": 9.892319525326888e-06,
      "loss": 0.1877,
      "step": 9700
    },
    {
      "epoch": 1.042669233237087,
      "grad_norm": 0.22697803378105164,
      "learning_rate": 9.837380507636526e-06,
      "loss": 0.1218,
      "step": 9750
    },
    {
      "epoch": 1.048016254945995,
      "grad_norm": 3.714355945587158,
      "learning_rate": 9.782441489946161e-06,
      "loss": 0.193,
      "step": 9800
    },
    {
      "epoch": 1.0533632766549033,
      "grad_norm": 0.28247350454330444,
      "learning_rate": 9.727502472255796e-06,
      "loss": 0.2097,
      "step": 9850
    },
    {
      "epoch": 1.0587102983638113,
      "grad_norm": 80.52139282226562,
      "learning_rate": 9.672563454565434e-06,
      "loss": 0.1347,
      "step": 9900
    },
    {
      "epoch": 1.0640573200727195,
      "grad_norm": 0.4654276371002197,
      "learning_rate": 9.617624436875069e-06,
      "loss": 0.1271,
      "step": 9950
    },
    {
      "epoch": 1.0694043417816277,
      "grad_norm": 12.817031860351562,
      "learning_rate": 9.562685419184706e-06,
      "loss": 0.2022,
      "step": 10000
    },
    {
      "epoch": 1.0747513634905357,
      "grad_norm": 7.278005599975586,
      "learning_rate": 9.507746401494342e-06,
      "loss": 0.1857,
      "step": 10050
    },
    {
      "epoch": 1.080098385199444,
      "grad_norm": 16.755704879760742,
      "learning_rate": 9.452807383803979e-06,
      "loss": 0.1374,
      "step": 10100
    },
    {
      "epoch": 1.0854454069083521,
      "grad_norm": 25.766660690307617,
      "learning_rate": 9.397868366113614e-06,
      "loss": 0.2416,
      "step": 10150
    },
    {
      "epoch": 1.0907924286172601,
      "grad_norm": 13.56789493560791,
      "learning_rate": 9.342929348423251e-06,
      "loss": 0.1321,
      "step": 10200
    },
    {
      "epoch": 1.0961394503261683,
      "grad_norm": 0.1217365562915802,
      "learning_rate": 9.287990330732889e-06,
      "loss": 0.1512,
      "step": 10250
    },
    {
      "epoch": 1.1014864720350765,
      "grad_norm": 30.787931442260742,
      "learning_rate": 9.233051313042524e-06,
      "loss": 0.1947,
      "step": 10300
    },
    {
      "epoch": 1.1068334937439845,
      "grad_norm": 0.17958496510982513,
      "learning_rate": 9.17811229535216e-06,
      "loss": 0.2392,
      "step": 10350
    },
    {
      "epoch": 1.1121805154528928,
      "grad_norm": 0.32951444387435913,
      "learning_rate": 9.123173277661797e-06,
      "loss": 0.1715,
      "step": 10400
    },
    {
      "epoch": 1.117527537161801,
      "grad_norm": 0.18835872411727905,
      "learning_rate": 9.068234259971432e-06,
      "loss": 0.1568,
      "step": 10450
    },
    {
      "epoch": 1.122874558870709,
      "grad_norm": 0.5639804601669312,
      "learning_rate": 9.013295242281068e-06,
      "loss": 0.2274,
      "step": 10500
    },
    {
      "epoch": 1.1282215805796172,
      "grad_norm": 0.1347169280052185,
      "learning_rate": 8.958356224590705e-06,
      "loss": 0.114,
      "step": 10550
    },
    {
      "epoch": 1.1335686022885252,
      "grad_norm": 0.2004213035106659,
      "learning_rate": 8.90341720690034e-06,
      "loss": 0.1508,
      "step": 10600
    },
    {
      "epoch": 1.1389156239974334,
      "grad_norm": 0.10120222717523575,
      "learning_rate": 8.848478189209977e-06,
      "loss": 0.1334,
      "step": 10650
    },
    {
      "epoch": 1.1442626457063416,
      "grad_norm": 0.114080511033535,
      "learning_rate": 8.793539171519615e-06,
      "loss": 0.2563,
      "step": 10700
    },
    {
      "epoch": 1.1496096674152496,
      "grad_norm": 0.1441688984632492,
      "learning_rate": 8.73860015382925e-06,
      "loss": 0.2674,
      "step": 10750
    },
    {
      "epoch": 1.1549566891241578,
      "grad_norm": 30.661638259887695,
      "learning_rate": 8.683661136138887e-06,
      "loss": 0.1655,
      "step": 10800
    },
    {
      "epoch": 1.160303710833066,
      "grad_norm": 55.548946380615234,
      "learning_rate": 8.628722118448523e-06,
      "loss": 0.1906,
      "step": 10850
    },
    {
      "epoch": 1.165650732541974,
      "grad_norm": 11.69448184967041,
      "learning_rate": 8.57378310075816e-06,
      "loss": 0.1867,
      "step": 10900
    },
    {
      "epoch": 1.1709977542508823,
      "grad_norm": 0.2544878125190735,
      "learning_rate": 8.518844083067795e-06,
      "loss": 0.2096,
      "step": 10950
    },
    {
      "epoch": 1.1763447759597905,
      "grad_norm": 13.153471946716309,
      "learning_rate": 8.46390506537743e-06,
      "loss": 0.264,
      "step": 11000
    },
    {
      "epoch": 1.1816917976686985,
      "grad_norm": 14.260746002197266,
      "learning_rate": 8.408966047687068e-06,
      "loss": 0.1736,
      "step": 11050
    },
    {
      "epoch": 1.1870388193776067,
      "grad_norm": 35.56288528442383,
      "learning_rate": 8.354027029996703e-06,
      "loss": 0.1725,
      "step": 11100
    },
    {
      "epoch": 1.192385841086515,
      "grad_norm": 14.370243072509766,
      "learning_rate": 8.29908801230634e-06,
      "loss": 0.177,
      "step": 11150
    },
    {
      "epoch": 1.197732862795423,
      "grad_norm": 0.12058909982442856,
      "learning_rate": 8.244148994615978e-06,
      "loss": 0.1385,
      "step": 11200
    },
    {
      "epoch": 1.2030798845043311,
      "grad_norm": 0.1024261862039566,
      "learning_rate": 8.189209976925613e-06,
      "loss": 0.1433,
      "step": 11250
    },
    {
      "epoch": 1.2084269062132393,
      "grad_norm": 1.161719560623169,
      "learning_rate": 8.13427095923525e-06,
      "loss": 0.1748,
      "step": 11300
    },
    {
      "epoch": 1.2137739279221473,
      "grad_norm": 0.29529449343681335,
      "learning_rate": 8.079331941544886e-06,
      "loss": 0.2359,
      "step": 11350
    },
    {
      "epoch": 1.2191209496310556,
      "grad_norm": 2.3261451721191406,
      "learning_rate": 8.024392923854523e-06,
      "loss": 0.196,
      "step": 11400
    },
    {
      "epoch": 1.2244679713399635,
      "grad_norm": 12.97737979888916,
      "learning_rate": 7.969453906164158e-06,
      "loss": 0.1504,
      "step": 11450
    },
    {
      "epoch": 1.2298149930488718,
      "grad_norm": 57.86610412597656,
      "learning_rate": 7.914514888473794e-06,
      "loss": 0.1316,
      "step": 11500
    },
    {
      "epoch": 1.23516201475778,
      "grad_norm": 2.93886661529541,
      "learning_rate": 7.859575870783431e-06,
      "loss": 0.1429,
      "step": 11550
    },
    {
      "epoch": 1.240509036466688,
      "grad_norm": 0.06898829340934753,
      "learning_rate": 7.804636853093066e-06,
      "loss": 0.0964,
      "step": 11600
    },
    {
      "epoch": 1.2458560581755962,
      "grad_norm": 4.258726119995117,
      "learning_rate": 7.749697835402704e-06,
      "loss": 0.2959,
      "step": 11650
    },
    {
      "epoch": 1.2512030798845044,
      "grad_norm": 1.4099458456039429,
      "learning_rate": 7.69475881771234e-06,
      "loss": 0.1227,
      "step": 11700
    },
    {
      "epoch": 1.2565501015934124,
      "grad_norm": 0.6527367830276489,
      "learning_rate": 7.639819800021976e-06,
      "loss": 0.1769,
      "step": 11750
    },
    {
      "epoch": 1.2618971233023206,
      "grad_norm": 0.20611709356307983,
      "learning_rate": 7.5848807823316125e-06,
      "loss": 0.1144,
      "step": 11800
    },
    {
      "epoch": 1.2672441450112286,
      "grad_norm": 47.128108978271484,
      "learning_rate": 7.529941764641249e-06,
      "loss": 0.2392,
      "step": 11850
    },
    {
      "epoch": 1.2725911667201368,
      "grad_norm": 0.08245513588190079,
      "learning_rate": 7.475002746950886e-06,
      "loss": 0.1625,
      "step": 11900
    },
    {
      "epoch": 1.277938188429045,
      "grad_norm": 0.508009672164917,
      "learning_rate": 7.4200637292605214e-06,
      "loss": 0.1471,
      "step": 11950
    },
    {
      "epoch": 1.283285210137953,
      "grad_norm": 0.06583692878484726,
      "learning_rate": 7.365124711570158e-06,
      "loss": 0.1561,
      "step": 12000
    },
    {
      "epoch": 1.2886322318468613,
      "grad_norm": 0.0306937824934721,
      "learning_rate": 7.310185693879794e-06,
      "loss": 0.1722,
      "step": 12050
    },
    {
      "epoch": 1.2939792535557695,
      "grad_norm": 22.67554473876953,
      "learning_rate": 7.25524667618943e-06,
      "loss": 0.191,
      "step": 12100
    },
    {
      "epoch": 1.2993262752646775,
      "grad_norm": 0.04014010727405548,
      "learning_rate": 7.200307658499066e-06,
      "loss": 0.096,
      "step": 12150
    },
    {
      "epoch": 1.3046732969735857,
      "grad_norm": 0.2142941802740097,
      "learning_rate": 7.145368640808703e-06,
      "loss": 0.2069,
      "step": 12200
    },
    {
      "epoch": 1.310020318682494,
      "grad_norm": 17.162755966186523,
      "learning_rate": 7.090429623118339e-06,
      "loss": 0.1879,
      "step": 12250
    },
    {
      "epoch": 1.315367340391402,
      "grad_norm": 0.14656206965446472,
      "learning_rate": 7.035490605427976e-06,
      "loss": 0.1754,
      "step": 12300
    },
    {
      "epoch": 1.3207143621003101,
      "grad_norm": 85.79597473144531,
      "learning_rate": 6.980551587737612e-06,
      "loss": 0.1665,
      "step": 12350
    },
    {
      "epoch": 1.3260613838092183,
      "grad_norm": 0.05066214129328728,
      "learning_rate": 6.925612570047247e-06,
      "loss": 0.2117,
      "step": 12400
    },
    {
      "epoch": 1.3314084055181263,
      "grad_norm": 0.04479064792394638,
      "learning_rate": 6.8706735523568845e-06,
      "loss": 0.122,
      "step": 12450
    },
    {
      "epoch": 1.3367554272270346,
      "grad_norm": 0.1162719577550888,
      "learning_rate": 6.815734534666521e-06,
      "loss": 0.2372,
      "step": 12500
    },
    {
      "epoch": 1.3421024489359428,
      "grad_norm": 0.06225883960723877,
      "learning_rate": 6.760795516976157e-06,
      "loss": 0.157,
      "step": 12550
    },
    {
      "epoch": 1.3474494706448508,
      "grad_norm": 29.210416793823242,
      "learning_rate": 6.7058564992857935e-06,
      "loss": 0.1981,
      "step": 12600
    },
    {
      "epoch": 1.352796492353759,
      "grad_norm": 0.15679015219211578,
      "learning_rate": 6.650917481595429e-06,
      "loss": 0.2327,
      "step": 12650
    },
    {
      "epoch": 1.3581435140626672,
      "grad_norm": 65.713623046875,
      "learning_rate": 6.595978463905066e-06,
      "loss": 0.1646,
      "step": 12700
    },
    {
      "epoch": 1.3634905357715752,
      "grad_norm": 13.128118515014648,
      "learning_rate": 6.541039446214702e-06,
      "loss": 0.1567,
      "step": 12750
    },
    {
      "epoch": 1.3688375574804834,
      "grad_norm": 0.35942524671554565,
      "learning_rate": 6.486100428524339e-06,
      "loss": 0.1897,
      "step": 12800
    },
    {
      "epoch": 1.3741845791893916,
      "grad_norm": 0.4309180974960327,
      "learning_rate": 6.431161410833975e-06,
      "loss": 0.2594,
      "step": 12850
    },
    {
      "epoch": 1.3795316008982996,
      "grad_norm": 0.1623842716217041,
      "learning_rate": 6.3762223931436105e-06,
      "loss": 0.1501,
      "step": 12900
    },
    {
      "epoch": 1.3848786226072078,
      "grad_norm": 6.888542175292969,
      "learning_rate": 6.321283375453248e-06,
      "loss": 0.188,
      "step": 12950
    },
    {
      "epoch": 1.390225644316116,
      "grad_norm": 0.1352631002664566,
      "learning_rate": 6.266344357762884e-06,
      "loss": 0.2463,
      "step": 13000
    },
    {
      "epoch": 1.395572666025024,
      "grad_norm": 0.0744771659374237,
      "learning_rate": 6.21140534007252e-06,
      "loss": 0.1736,
      "step": 13050
    },
    {
      "epoch": 1.4009196877339323,
      "grad_norm": 0.12591733038425446,
      "learning_rate": 6.1564663223821566e-06,
      "loss": 0.1398,
      "step": 13100
    },
    {
      "epoch": 1.4062667094428403,
      "grad_norm": 0.0938166007399559,
      "learning_rate": 6.101527304691792e-06,
      "loss": 0.1664,
      "step": 13150
    },
    {
      "epoch": 1.4116137311517485,
      "grad_norm": 0.17048677802085876,
      "learning_rate": 6.046588287001429e-06,
      "loss": 0.1918,
      "step": 13200
    },
    {
      "epoch": 1.4169607528606565,
      "grad_norm": 0.045795802026987076,
      "learning_rate": 5.991649269311065e-06,
      "loss": 0.1931,
      "step": 13250
    },
    {
      "epoch": 1.4223077745695647,
      "grad_norm": 14.997848510742188,
      "learning_rate": 5.936710251620702e-06,
      "loss": 0.1487,
      "step": 13300
    },
    {
      "epoch": 1.427654796278473,
      "grad_norm": 0.5142520070075989,
      "learning_rate": 5.881771233930338e-06,
      "loss": 0.2708,
      "step": 13350
    },
    {
      "epoch": 1.433001817987381,
      "grad_norm": 0.22156481444835663,
      "learning_rate": 5.8268322162399736e-06,
      "loss": 0.1906,
      "step": 13400
    },
    {
      "epoch": 1.4383488396962891,
      "grad_norm": 0.07908584177494049,
      "learning_rate": 5.771893198549611e-06,
      "loss": 0.1616,
      "step": 13450
    },
    {
      "epoch": 1.4436958614051973,
      "grad_norm": 14.610077857971191,
      "learning_rate": 5.716954180859246e-06,
      "loss": 0.1718,
      "step": 13500
    },
    {
      "epoch": 1.4490428831141053,
      "grad_norm": 50.18034362792969,
      "learning_rate": 5.662015163168883e-06,
      "loss": 0.2185,
      "step": 13550
    },
    {
      "epoch": 1.4543899048230136,
      "grad_norm": 8.26224136352539,
      "learning_rate": 5.60707614547852e-06,
      "loss": 0.1945,
      "step": 13600
    },
    {
      "epoch": 1.4597369265319218,
      "grad_norm": 87.56442260742188,
      "learning_rate": 5.552137127788155e-06,
      "loss": 0.1758,
      "step": 13650
    },
    {
      "epoch": 1.4650839482408298,
      "grad_norm": 0.09521479159593582,
      "learning_rate": 5.497198110097792e-06,
      "loss": 0.119,
      "step": 13700
    },
    {
      "epoch": 1.470430969949738,
      "grad_norm": 4.567956447601318,
      "learning_rate": 5.442259092407428e-06,
      "loss": 0.1382,
      "step": 13750
    },
    {
      "epoch": 1.4757779916586462,
      "grad_norm": 0.12758927047252655,
      "learning_rate": 5.387320074717064e-06,
      "loss": 0.2523,
      "step": 13800
    },
    {
      "epoch": 1.4811250133675542,
      "grad_norm": 5.767886161804199,
      "learning_rate": 5.332381057026701e-06,
      "loss": 0.2172,
      "step": 13850
    },
    {
      "epoch": 1.4864720350764624,
      "grad_norm": 0.19935347139835358,
      "learning_rate": 5.277442039336337e-06,
      "loss": 0.0958,
      "step": 13900
    },
    {
      "epoch": 1.4918190567853706,
      "grad_norm": 0.11376260221004486,
      "learning_rate": 5.222503021645974e-06,
      "loss": 0.1539,
      "step": 13950
    },
    {
      "epoch": 1.4971660784942786,
      "grad_norm": 0.8916886448860168,
      "learning_rate": 5.167564003955609e-06,
      "loss": 0.2044,
      "step": 14000
    },
    {
      "epoch": 1.5025131002031868,
      "grad_norm": 30.906129837036133,
      "learning_rate": 5.112624986265246e-06,
      "loss": 0.1248,
      "step": 14050
    },
    {
      "epoch": 1.507860121912095,
      "grad_norm": 8.938861846923828,
      "learning_rate": 5.057685968574883e-06,
      "loss": 0.0678,
      "step": 14100
    },
    {
      "epoch": 1.513207143621003,
      "grad_norm": 9.061383247375488,
      "learning_rate": 5.002746950884518e-06,
      "loss": 0.2514,
      "step": 14150
    },
    {
      "epoch": 1.5185541653299113,
      "grad_norm": 0.5444339513778687,
      "learning_rate": 4.9478079331941545e-06,
      "loss": 0.1346,
      "step": 14200
    },
    {
      "epoch": 1.5239011870388195,
      "grad_norm": 9.599190711975098,
      "learning_rate": 4.892868915503791e-06,
      "loss": 0.1712,
      "step": 14250
    },
    {
      "epoch": 1.5292482087477275,
      "grad_norm": 26.442646026611328,
      "learning_rate": 4.837929897813428e-06,
      "loss": 0.1588,
      "step": 14300
    },
    {
      "epoch": 1.5345952304566357,
      "grad_norm": 1.9747495651245117,
      "learning_rate": 4.782990880123064e-06,
      "loss": 0.163,
      "step": 14350
    },
    {
      "epoch": 1.539942252165544,
      "grad_norm": 0.06808646768331528,
      "learning_rate": 4.7280518624327e-06,
      "loss": 0.2038,
      "step": 14400
    },
    {
      "epoch": 1.545289273874452,
      "grad_norm": 8.169157981872559,
      "learning_rate": 4.673112844742336e-06,
      "loss": 0.1476,
      "step": 14450
    },
    {
      "epoch": 1.55063629558336,
      "grad_norm": 0.046578504145145416,
      "learning_rate": 4.618173827051972e-06,
      "loss": 0.1354,
      "step": 14500
    },
    {
      "epoch": 1.5559833172922684,
      "grad_norm": 0.09055232256650925,
      "learning_rate": 4.5632348093616095e-06,
      "loss": 0.0666,
      "step": 14550
    },
    {
      "epoch": 1.5613303390011763,
      "grad_norm": 0.06868033111095428,
      "learning_rate": 4.508295791671246e-06,
      "loss": 0.1366,
      "step": 14600
    },
    {
      "epoch": 1.5666773607100843,
      "grad_norm": 12.24983024597168,
      "learning_rate": 4.453356773980881e-06,
      "loss": 0.1453,
      "step": 14650
    },
    {
      "epoch": 1.5720243824189928,
      "grad_norm": 5.720213890075684,
      "learning_rate": 4.398417756290518e-06,
      "loss": 0.1547,
      "step": 14700
    },
    {
      "epoch": 1.5773714041279008,
      "grad_norm": 0.05208950862288475,
      "learning_rate": 4.343478738600154e-06,
      "loss": 0.1729,
      "step": 14750
    },
    {
      "epoch": 1.5827184258368088,
      "grad_norm": 5.849822521209717,
      "learning_rate": 4.28853972090979e-06,
      "loss": 0.1412,
      "step": 14800
    },
    {
      "epoch": 1.588065447545717,
      "grad_norm": 7.93712854385376,
      "learning_rate": 4.2336007032194265e-06,
      "loss": 0.2029,
      "step": 14850
    },
    {
      "epoch": 1.5934124692546252,
      "grad_norm": 0.4970201551914215,
      "learning_rate": 4.178661685529063e-06,
      "loss": 0.2019,
      "step": 14900
    },
    {
      "epoch": 1.5987594909635332,
      "grad_norm": 0.6850066781044006,
      "learning_rate": 4.123722667838699e-06,
      "loss": 0.1561,
      "step": 14950
    },
    {
      "epoch": 1.6041065126724414,
      "grad_norm": 5.503690242767334,
      "learning_rate": 4.0687836501483355e-06,
      "loss": 0.1336,
      "step": 15000
    },
    {
      "epoch": 1.6094535343813496,
      "grad_norm": 30.87784194946289,
      "learning_rate": 4.013844632457972e-06,
      "loss": 0.1406,
      "step": 15050
    },
    {
      "epoch": 1.6148005560902576,
      "grad_norm": 0.09102261811494827,
      "learning_rate": 3.958905614767608e-06,
      "loss": 0.154,
      "step": 15100
    },
    {
      "epoch": 1.6201475777991659,
      "grad_norm": 8.243748664855957,
      "learning_rate": 3.903966597077244e-06,
      "loss": 0.1808,
      "step": 15150
    },
    {
      "epoch": 1.625494599508074,
      "grad_norm": 0.23772522807121277,
      "learning_rate": 3.849027579386881e-06,
      "loss": 0.1475,
      "step": 15200
    },
    {
      "epoch": 1.630841621216982,
      "grad_norm": 0.935803234577179,
      "learning_rate": 3.7940885616965174e-06,
      "loss": 0.0847,
      "step": 15250
    },
    {
      "epoch": 1.6361886429258903,
      "grad_norm": 0.16779156029224396,
      "learning_rate": 3.7391495440061538e-06,
      "loss": 0.2277,
      "step": 15300
    },
    {
      "epoch": 1.6415356646347985,
      "grad_norm": 0.2994992434978485,
      "learning_rate": 3.6842105263157896e-06,
      "loss": 0.1568,
      "step": 15350
    },
    {
      "epoch": 1.6468826863437065,
      "grad_norm": 0.06110190972685814,
      "learning_rate": 3.629271508625426e-06,
      "loss": 0.1885,
      "step": 15400
    },
    {
      "epoch": 1.6522297080526147,
      "grad_norm": 0.04068871587514877,
      "learning_rate": 3.5743324909350623e-06,
      "loss": 0.1524,
      "step": 15450
    },
    {
      "epoch": 1.657576729761523,
      "grad_norm": 0.1161041334271431,
      "learning_rate": 3.519393473244699e-06,
      "loss": 0.1597,
      "step": 15500
    },
    {
      "epoch": 1.662923751470431,
      "grad_norm": 0.09325697273015976,
      "learning_rate": 3.4644544555543353e-06,
      "loss": 0.1642,
      "step": 15550
    },
    {
      "epoch": 1.6682707731793391,
      "grad_norm": 7.822939395904541,
      "learning_rate": 3.409515437863971e-06,
      "loss": 0.1217,
      "step": 15600
    },
    {
      "epoch": 1.6736177948882474,
      "grad_norm": 0.05491524934768677,
      "learning_rate": 3.3545764201736075e-06,
      "loss": 0.1353,
      "step": 15650
    },
    {
      "epoch": 1.6789648165971554,
      "grad_norm": 30.581941604614258,
      "learning_rate": 3.299637402483244e-06,
      "loss": 0.16,
      "step": 15700
    },
    {
      "epoch": 1.6843118383060636,
      "grad_norm": 6.688569068908691,
      "learning_rate": 3.2446983847928805e-06,
      "loss": 0.1685,
      "step": 15750
    },
    {
      "epoch": 1.6896588600149718,
      "grad_norm": 38.128238677978516,
      "learning_rate": 3.189759367102516e-06,
      "loss": 0.1305,
      "step": 15800
    },
    {
      "epoch": 1.6950058817238798,
      "grad_norm": 0.32214590907096863,
      "learning_rate": 3.1348203494121527e-06,
      "loss": 0.1651,
      "step": 15850
    },
    {
      "epoch": 1.7003529034327878,
      "grad_norm": 20.569395065307617,
      "learning_rate": 3.079881331721789e-06,
      "loss": 0.1798,
      "step": 15900
    },
    {
      "epoch": 1.7056999251416962,
      "grad_norm": 0.11306682974100113,
      "learning_rate": 3.0249423140314254e-06,
      "loss": 0.1488,
      "step": 15950
    },
    {
      "epoch": 1.7110469468506042,
      "grad_norm": 0.08867275714874268,
      "learning_rate": 2.970003296341062e-06,
      "loss": 0.1725,
      "step": 16000
    },
    {
      "epoch": 1.7163939685595122,
      "grad_norm": 89.68354797363281,
      "learning_rate": 2.9150642786506976e-06,
      "loss": 0.1382,
      "step": 16050
    },
    {
      "epoch": 1.7217409902684206,
      "grad_norm": 0.17664484679698944,
      "learning_rate": 2.8601252609603343e-06,
      "loss": 0.1764,
      "step": 16100
    },
    {
      "epoch": 1.7270880119773286,
      "grad_norm": 0.2689102590084076,
      "learning_rate": 2.8051862432699706e-06,
      "loss": 0.1585,
      "step": 16150
    },
    {
      "epoch": 1.7324350336862366,
      "grad_norm": 0.04321036860346794,
      "learning_rate": 2.750247225579607e-06,
      "loss": 0.1848,
      "step": 16200
    },
    {
      "epoch": 1.7377820553951449,
      "grad_norm": 0.2880881130695343,
      "learning_rate": 2.6953082078892432e-06,
      "loss": 0.1495,
      "step": 16250
    },
    {
      "epoch": 1.743129077104053,
      "grad_norm": 0.35320350527763367,
      "learning_rate": 2.640369190198879e-06,
      "loss": 0.2009,
      "step": 16300
    },
    {
      "epoch": 1.748476098812961,
      "grad_norm": 0.035278599709272385,
      "learning_rate": 2.585430172508516e-06,
      "loss": 0.2064,
      "step": 16350
    },
    {
      "epoch": 1.7538231205218693,
      "grad_norm": 0.08543681353330612,
      "learning_rate": 2.530491154818152e-06,
      "loss": 0.151,
      "step": 16400
    },
    {
      "epoch": 1.7591701422307775,
      "grad_norm": 20.574920654296875,
      "learning_rate": 2.4755521371277885e-06,
      "loss": 0.1635,
      "step": 16450
    },
    {
      "epoch": 1.7645171639396855,
      "grad_norm": 29.894935607910156,
      "learning_rate": 2.4206131194374248e-06,
      "loss": 0.1604,
      "step": 16500
    },
    {
      "epoch": 1.7698641856485937,
      "grad_norm": 13.633512496948242,
      "learning_rate": 2.365674101747061e-06,
      "loss": 0.1725,
      "step": 16550
    },
    {
      "epoch": 1.775211207357502,
      "grad_norm": 0.15571948885917664,
      "learning_rate": 2.3107350840566974e-06,
      "loss": 0.1197,
      "step": 16600
    },
    {
      "epoch": 1.78055822906641,
      "grad_norm": 70.85848999023438,
      "learning_rate": 2.2557960663663337e-06,
      "loss": 0.188,
      "step": 16650
    },
    {
      "epoch": 1.7859052507753181,
      "grad_norm": 0.08787797391414642,
      "learning_rate": 2.2008570486759696e-06,
      "loss": 0.1144,
      "step": 16700
    },
    {
      "epoch": 1.7912522724842264,
      "grad_norm": 1.0468087196350098,
      "learning_rate": 2.1459180309856063e-06,
      "loss": 0.1573,
      "step": 16750
    },
    {
      "epoch": 1.7965992941931344,
      "grad_norm": 0.026742765679955482,
      "learning_rate": 2.090979013295242e-06,
      "loss": 0.1584,
      "step": 16800
    },
    {
      "epoch": 1.8019463159020426,
      "grad_norm": 0.31063687801361084,
      "learning_rate": 2.036039995604879e-06,
      "loss": 0.1216,
      "step": 16850
    },
    {
      "epoch": 1.8072933376109508,
      "grad_norm": 2.9792962074279785,
      "learning_rate": 1.9811009779145152e-06,
      "loss": 0.1614,
      "step": 16900
    },
    {
      "epoch": 1.8126403593198588,
      "grad_norm": 11.549944877624512,
      "learning_rate": 1.926161960224151e-06,
      "loss": 0.1581,
      "step": 16950
    },
    {
      "epoch": 1.817987381028767,
      "grad_norm": 1.582040786743164,
      "learning_rate": 1.8712229425337876e-06,
      "loss": 0.1772,
      "step": 17000
    },
    {
      "epoch": 1.8233344027376752,
      "grad_norm": 0.47772979736328125,
      "learning_rate": 1.816283924843424e-06,
      "loss": 0.2197,
      "step": 17050
    },
    {
      "epoch": 1.8286814244465832,
      "grad_norm": 4.317905902862549,
      "learning_rate": 1.7613449071530603e-06,
      "loss": 0.0959,
      "step": 17100
    },
    {
      "epoch": 1.8340284461554914,
      "grad_norm": 0.06932906806468964,
      "learning_rate": 1.7064058894626964e-06,
      "loss": 0.1824,
      "step": 17150
    },
    {
      "epoch": 1.8393754678643996,
      "grad_norm": 17.440603256225586,
      "learning_rate": 1.6514668717723329e-06,
      "loss": 0.1362,
      "step": 17200
    },
    {
      "epoch": 1.8447224895733076,
      "grad_norm": 0.11679866909980774,
      "learning_rate": 1.5965278540819692e-06,
      "loss": 0.1732,
      "step": 17250
    },
    {
      "epoch": 1.8500695112822156,
      "grad_norm": 0.04901403933763504,
      "learning_rate": 1.5415888363916053e-06,
      "loss": 0.2648,
      "step": 17300
    },
    {
      "epoch": 1.855416532991124,
      "grad_norm": 30.098215103149414,
      "learning_rate": 1.4866498187012418e-06,
      "loss": 0.1635,
      "step": 17350
    },
    {
      "epoch": 1.860763554700032,
      "grad_norm": 8.782958984375,
      "learning_rate": 1.431710801010878e-06,
      "loss": 0.221,
      "step": 17400
    },
    {
      "epoch": 1.86611057640894,
      "grad_norm": 0.05787831172347069,
      "learning_rate": 1.3767717833205144e-06,
      "loss": 0.1449,
      "step": 17450
    },
    {
      "epoch": 1.8714575981178485,
      "grad_norm": 57.844154357910156,
      "learning_rate": 1.3218327656301505e-06,
      "loss": 0.1679,
      "step": 17500
    },
    {
      "epoch": 1.8768046198267565,
      "grad_norm": 0.7091411352157593,
      "learning_rate": 1.2668937479397868e-06,
      "loss": 0.13,
      "step": 17550
    },
    {
      "epoch": 1.8821516415356645,
      "grad_norm": 0.10797777026891708,
      "learning_rate": 1.2119547302494231e-06,
      "loss": 0.1869,
      "step": 17600
    },
    {
      "epoch": 1.887498663244573,
      "grad_norm": 0.1852327585220337,
      "learning_rate": 1.1570157125590595e-06,
      "loss": 0.1577,
      "step": 17650
    },
    {
      "epoch": 1.892845684953481,
      "grad_norm": 0.6073570847511292,
      "learning_rate": 1.102076694868696e-06,
      "loss": 0.1249,
      "step": 17700
    },
    {
      "epoch": 1.898192706662389,
      "grad_norm": 0.5585874319076538,
      "learning_rate": 1.047137677178332e-06,
      "loss": 0.1563,
      "step": 17750
    },
    {
      "epoch": 1.9035397283712971,
      "grad_norm": 3.373891830444336,
      "learning_rate": 9.921986594879684e-07,
      "loss": 0.1954,
      "step": 17800
    },
    {
      "epoch": 1.9088867500802054,
      "grad_norm": 28.58983039855957,
      "learning_rate": 9.372596417976047e-07,
      "loss": 0.1456,
      "step": 17850
    },
    {
      "epoch": 1.9142337717891134,
      "grad_norm": 7.807586669921875,
      "learning_rate": 8.82320624107241e-07,
      "loss": 0.165,
      "step": 17900
    },
    {
      "epoch": 1.9195807934980216,
      "grad_norm": 0.9926326870918274,
      "learning_rate": 8.273816064168773e-07,
      "loss": 0.1785,
      "step": 17950
    },
    {
      "epoch": 1.9249278152069298,
      "grad_norm": 12.424480438232422,
      "learning_rate": 7.724425887265135e-07,
      "loss": 0.2636,
      "step": 18000
    },
    {
      "epoch": 1.9302748369158378,
      "grad_norm": 0.1759042590856552,
      "learning_rate": 7.175035710361499e-07,
      "loss": 0.2908,
      "step": 18050
    },
    {
      "epoch": 1.935621858624746,
      "grad_norm": 0.07523142546415329,
      "learning_rate": 6.625645533457862e-07,
      "loss": 0.1447,
      "step": 18100
    },
    {
      "epoch": 1.9409688803336542,
      "grad_norm": 0.29872605204582214,
      "learning_rate": 6.076255356554226e-07,
      "loss": 0.1788,
      "step": 18150
    },
    {
      "epoch": 1.9463159020425622,
      "grad_norm": 64.8734359741211,
      "learning_rate": 5.526865179650589e-07,
      "loss": 0.1373,
      "step": 18200
    },
    {
      "epoch": 1.9516629237514704,
      "grad_norm": 0.19409196078777313,
      "learning_rate": 4.977475002746951e-07,
      "loss": 0.1634,
      "step": 18250
    },
    {
      "epoch": 1.9570099454603787,
      "grad_norm": 0.09909514337778091,
      "learning_rate": 4.4280848258433143e-07,
      "loss": 0.1822,
      "step": 18300
    },
    {
      "epoch": 1.9623569671692866,
      "grad_norm": 0.054291531443595886,
      "learning_rate": 3.8786946489396774e-07,
      "loss": 0.1134,
      "step": 18350
    },
    {
      "epoch": 1.9677039888781949,
      "grad_norm": 0.09147386997938156,
      "learning_rate": 3.32930447203604e-07,
      "loss": 0.1485,
      "step": 18400
    },
    {
      "epoch": 1.973051010587103,
      "grad_norm": 0.19019819796085358,
      "learning_rate": 2.779914295132403e-07,
      "loss": 0.1294,
      "step": 18450
    },
    {
      "epoch": 1.978398032296011,
      "grad_norm": 60.864749908447266,
      "learning_rate": 2.230524118228766e-07,
      "loss": 0.1386,
      "step": 18500
    },
    {
      "epoch": 1.9837450540049193,
      "grad_norm": 96.0314712524414,
      "learning_rate": 1.6811339413251295e-07,
      "loss": 0.0727,
      "step": 18550
    },
    {
      "epoch": 1.9890920757138275,
      "grad_norm": 2.9088189601898193,
      "learning_rate": 1.1317437644214922e-07,
      "loss": 0.0827,
      "step": 18600
    },
    {
      "epoch": 1.9944390974227355,
      "grad_norm": 0.40643349289894104,
      "learning_rate": 5.823535875178552e-08,
      "loss": 0.1241,
      "step": 18650
    },
    {
      "epoch": 1.9997861191316437,
      "grad_norm": 1.3758718967437744,
      "learning_rate": 3.2963410614218217e-09,
      "loss": 0.1763,
      "step": 18700
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.950058817238798,
      "eval_f1": 0.9558141735263507,
      "eval_loss": 0.21287749707698822,
      "eval_precision": 0.9666060664051287,
      "eval_recall": 0.9452605969869935,
      "eval_runtime": 2387.9664,
      "eval_samples_per_second": 7.832,
      "eval_steps_per_second": 0.245,
      "step": 18702
    }
  ],
  "logging_steps": 50,
  "max_steps": 18702,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9909488691259392.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
