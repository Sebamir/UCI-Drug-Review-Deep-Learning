{
  "best_global_step": 9351,
  "best_metric": 0.21732069551944733,
  "best_model_checkpoint": "results\\stage_1_unfrozen\\checkpoint-9351",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 9351,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005347021708908138,
      "grad_norm": 1.378805160522461,
      "learning_rate": 1.9600000000000003e-06,
      "loss": 0.6926,
      "step": 50
    },
    {
      "epoch": 0.010694043417816277,
      "grad_norm": 1.4336763620376587,
      "learning_rate": 3.96e-06,
      "loss": 0.6845,
      "step": 100
    },
    {
      "epoch": 0.016041065126724416,
      "grad_norm": 3.4670872688293457,
      "learning_rate": 5.9600000000000005e-06,
      "loss": 0.6875,
      "step": 150
    },
    {
      "epoch": 0.021388086835632553,
      "grad_norm": 2.028843402862549,
      "learning_rate": 7.960000000000002e-06,
      "loss": 0.6711,
      "step": 200
    },
    {
      "epoch": 0.02673510854454069,
      "grad_norm": 4.351315975189209,
      "learning_rate": 9.960000000000001e-06,
      "loss": 0.6082,
      "step": 250
    },
    {
      "epoch": 0.03208213025344883,
      "grad_norm": 11.395781517028809,
      "learning_rate": 1.196e-05,
      "loss": 0.511,
      "step": 300
    },
    {
      "epoch": 0.037429151962356966,
      "grad_norm": 17.680309295654297,
      "learning_rate": 1.396e-05,
      "loss": 0.4608,
      "step": 350
    },
    {
      "epoch": 0.04277617367126511,
      "grad_norm": 8.01715087890625,
      "learning_rate": 1.5960000000000003e-05,
      "loss": 0.4785,
      "step": 400
    },
    {
      "epoch": 0.04812319538017324,
      "grad_norm": 16.327306747436523,
      "learning_rate": 1.796e-05,
      "loss": 0.4176,
      "step": 450
    },
    {
      "epoch": 0.05347021708908138,
      "grad_norm": 14.848443984985352,
      "learning_rate": 1.9960000000000002e-05,
      "loss": 0.4019,
      "step": 500
    },
    {
      "epoch": 0.05881723879798952,
      "grad_norm": 15.741288185119629,
      "learning_rate": 1.9946159762663445e-05,
      "loss": 0.4618,
      "step": 550
    },
    {
      "epoch": 0.06416426050689766,
      "grad_norm": 1.3692936897277832,
      "learning_rate": 1.9891220744973082e-05,
      "loss": 0.3322,
      "step": 600
    },
    {
      "epoch": 0.0695112822158058,
      "grad_norm": 12.6097412109375,
      "learning_rate": 1.983628172728272e-05,
      "loss": 0.4171,
      "step": 650
    },
    {
      "epoch": 0.07485830392471393,
      "grad_norm": 2.472531318664551,
      "learning_rate": 1.9781342709592356e-05,
      "loss": 0.3694,
      "step": 700
    },
    {
      "epoch": 0.08020532563362208,
      "grad_norm": 12.704851150512695,
      "learning_rate": 1.972640369190199e-05,
      "loss": 0.405,
      "step": 750
    },
    {
      "epoch": 0.08555234734253021,
      "grad_norm": 30.13095474243164,
      "learning_rate": 1.9671464674211627e-05,
      "loss": 0.3766,
      "step": 800
    },
    {
      "epoch": 0.09089936905143835,
      "grad_norm": 2.8249127864837646,
      "learning_rate": 1.9616525656521264e-05,
      "loss": 0.3855,
      "step": 850
    },
    {
      "epoch": 0.09624639076034648,
      "grad_norm": 3.663248062133789,
      "learning_rate": 1.9561586638830898e-05,
      "loss": 0.4228,
      "step": 900
    },
    {
      "epoch": 0.10159341246925463,
      "grad_norm": 1.1196235418319702,
      "learning_rate": 1.9506647621140535e-05,
      "loss": 0.3765,
      "step": 950
    },
    {
      "epoch": 0.10694043417816276,
      "grad_norm": 13.400036811828613,
      "learning_rate": 1.9451708603450172e-05,
      "loss": 0.3395,
      "step": 1000
    },
    {
      "epoch": 0.1122874558870709,
      "grad_norm": 6.569674491882324,
      "learning_rate": 1.939676958575981e-05,
      "loss": 0.4211,
      "step": 1050
    },
    {
      "epoch": 0.11763447759597905,
      "grad_norm": 2.7657294273376465,
      "learning_rate": 1.9341830568069443e-05,
      "loss": 0.3425,
      "step": 1100
    },
    {
      "epoch": 0.12298149930488718,
      "grad_norm": 7.33969259262085,
      "learning_rate": 1.928689155037908e-05,
      "loss": 0.3805,
      "step": 1150
    },
    {
      "epoch": 0.12832852101379533,
      "grad_norm": 0.8315293788909912,
      "learning_rate": 1.9231952532688717e-05,
      "loss": 0.3115,
      "step": 1200
    },
    {
      "epoch": 0.13367554272270346,
      "grad_norm": 16.877418518066406,
      "learning_rate": 1.917701351499835e-05,
      "loss": 0.3408,
      "step": 1250
    },
    {
      "epoch": 0.1390225644316116,
      "grad_norm": 14.575719833374023,
      "learning_rate": 1.912207449730799e-05,
      "loss": 0.4091,
      "step": 1300
    },
    {
      "epoch": 0.14436958614051973,
      "grad_norm": 10.32137680053711,
      "learning_rate": 1.9067135479617626e-05,
      "loss": 0.4213,
      "step": 1350
    },
    {
      "epoch": 0.14971660784942786,
      "grad_norm": 14.646960258483887,
      "learning_rate": 1.9012196461927263e-05,
      "loss": 0.3606,
      "step": 1400
    },
    {
      "epoch": 0.155063629558336,
      "grad_norm": 5.434014797210693,
      "learning_rate": 1.89572574442369e-05,
      "loss": 0.3533,
      "step": 1450
    },
    {
      "epoch": 0.16041065126724416,
      "grad_norm": 2.0011775493621826,
      "learning_rate": 1.8902318426546537e-05,
      "loss": 0.3239,
      "step": 1500
    },
    {
      "epoch": 0.1657576729761523,
      "grad_norm": 11.753279685974121,
      "learning_rate": 1.884737940885617e-05,
      "loss": 0.2946,
      "step": 1550
    },
    {
      "epoch": 0.17110469468506043,
      "grad_norm": 8.398914337158203,
      "learning_rate": 1.8792440391165808e-05,
      "loss": 0.3872,
      "step": 1600
    },
    {
      "epoch": 0.17645171639396856,
      "grad_norm": 12.33010482788086,
      "learning_rate": 1.8737501373475445e-05,
      "loss": 0.361,
      "step": 1650
    },
    {
      "epoch": 0.1817987381028767,
      "grad_norm": 12.254762649536133,
      "learning_rate": 1.8682562355785082e-05,
      "loss": 0.3533,
      "step": 1700
    },
    {
      "epoch": 0.18714575981178483,
      "grad_norm": 2.0727243423461914,
      "learning_rate": 1.8627623338094716e-05,
      "loss": 0.2926,
      "step": 1750
    },
    {
      "epoch": 0.19249278152069296,
      "grad_norm": 1.6039931774139404,
      "learning_rate": 1.8572684320404353e-05,
      "loss": 0.3356,
      "step": 1800
    },
    {
      "epoch": 0.19783980322960112,
      "grad_norm": 19.080467224121094,
      "learning_rate": 1.851774530271399e-05,
      "loss": 0.3619,
      "step": 1850
    },
    {
      "epoch": 0.20318682493850926,
      "grad_norm": 3.3939690589904785,
      "learning_rate": 1.8462806285023624e-05,
      "loss": 0.3285,
      "step": 1900
    },
    {
      "epoch": 0.2085338466474174,
      "grad_norm": 3.7839245796203613,
      "learning_rate": 1.840786726733326e-05,
      "loss": 0.296,
      "step": 1950
    },
    {
      "epoch": 0.21388086835632553,
      "grad_norm": 9.542397499084473,
      "learning_rate": 1.83529282496429e-05,
      "loss": 0.3228,
      "step": 2000
    },
    {
      "epoch": 0.21922789006523366,
      "grad_norm": 11.032031059265137,
      "learning_rate": 1.8297989231952532e-05,
      "loss": 0.3419,
      "step": 2050
    },
    {
      "epoch": 0.2245749117741418,
      "grad_norm": 17.0900936126709,
      "learning_rate": 1.824305021426217e-05,
      "loss": 0.3144,
      "step": 2100
    },
    {
      "epoch": 0.22992193348304993,
      "grad_norm": 8.812235832214355,
      "learning_rate": 1.8188111196571806e-05,
      "loss": 0.3789,
      "step": 2150
    },
    {
      "epoch": 0.2352689551919581,
      "grad_norm": 8.220836639404297,
      "learning_rate": 1.8133172178881444e-05,
      "loss": 0.319,
      "step": 2200
    },
    {
      "epoch": 0.24061597690086622,
      "grad_norm": 16.62322998046875,
      "learning_rate": 1.8078233161191077e-05,
      "loss": 0.323,
      "step": 2250
    },
    {
      "epoch": 0.24596299860977436,
      "grad_norm": 18.836570739746094,
      "learning_rate": 1.8023294143500715e-05,
      "loss": 0.3296,
      "step": 2300
    },
    {
      "epoch": 0.2513100203186825,
      "grad_norm": 16.95131492614746,
      "learning_rate": 1.7968355125810352e-05,
      "loss": 0.3311,
      "step": 2350
    },
    {
      "epoch": 0.25665704202759065,
      "grad_norm": 1.14356529712677,
      "learning_rate": 1.791341610811999e-05,
      "loss": 0.2435,
      "step": 2400
    },
    {
      "epoch": 0.26200406373649876,
      "grad_norm": 20.487897872924805,
      "learning_rate": 1.7858477090429626e-05,
      "loss": 0.306,
      "step": 2450
    },
    {
      "epoch": 0.2673510854454069,
      "grad_norm": 6.587573528289795,
      "learning_rate": 1.7803538072739263e-05,
      "loss": 0.3755,
      "step": 2500
    },
    {
      "epoch": 0.27269810715431503,
      "grad_norm": 34.0817985534668,
      "learning_rate": 1.7748599055048897e-05,
      "loss": 0.3277,
      "step": 2550
    },
    {
      "epoch": 0.2780451288632232,
      "grad_norm": 10.669944763183594,
      "learning_rate": 1.7693660037358534e-05,
      "loss": 0.3598,
      "step": 2600
    },
    {
      "epoch": 0.2833921505721313,
      "grad_norm": 7.044344425201416,
      "learning_rate": 1.763872101966817e-05,
      "loss": 0.3462,
      "step": 2650
    },
    {
      "epoch": 0.28873917228103946,
      "grad_norm": 16.4897518157959,
      "learning_rate": 1.758378200197781e-05,
      "loss": 0.3317,
      "step": 2700
    },
    {
      "epoch": 0.2940861939899476,
      "grad_norm": 6.035110950469971,
      "learning_rate": 1.7528842984287442e-05,
      "loss": 0.3511,
      "step": 2750
    },
    {
      "epoch": 0.2994332156988557,
      "grad_norm": 10.592534065246582,
      "learning_rate": 1.747390396659708e-05,
      "loss": 0.3208,
      "step": 2800
    },
    {
      "epoch": 0.3047802374077639,
      "grad_norm": 8.10433292388916,
      "learning_rate": 1.7418964948906716e-05,
      "loss": 0.3163,
      "step": 2850
    },
    {
      "epoch": 0.310127259116672,
      "grad_norm": 0.432722806930542,
      "learning_rate": 1.736402593121635e-05,
      "loss": 0.3267,
      "step": 2900
    },
    {
      "epoch": 0.31547428082558016,
      "grad_norm": 3.630265951156616,
      "learning_rate": 1.7309086913525987e-05,
      "loss": 0.3536,
      "step": 2950
    },
    {
      "epoch": 0.3208213025344883,
      "grad_norm": 29.886791229248047,
      "learning_rate": 1.7254147895835625e-05,
      "loss": 0.2491,
      "step": 3000
    },
    {
      "epoch": 0.3261683242433964,
      "grad_norm": 17.40411376953125,
      "learning_rate": 1.719920887814526e-05,
      "loss": 0.2787,
      "step": 3050
    },
    {
      "epoch": 0.3315153459523046,
      "grad_norm": 9.210959434509277,
      "learning_rate": 1.7144269860454895e-05,
      "loss": 0.3658,
      "step": 3100
    },
    {
      "epoch": 0.3368623676612127,
      "grad_norm": 19.992637634277344,
      "learning_rate": 1.7089330842764533e-05,
      "loss": 0.3617,
      "step": 3150
    },
    {
      "epoch": 0.34220938937012085,
      "grad_norm": 13.792549133300781,
      "learning_rate": 1.7034391825074166e-05,
      "loss": 0.2504,
      "step": 3200
    },
    {
      "epoch": 0.34755641107902896,
      "grad_norm": 16.035053253173828,
      "learning_rate": 1.6979452807383804e-05,
      "loss": 0.349,
      "step": 3250
    },
    {
      "epoch": 0.3529034327879371,
      "grad_norm": 0.7599762082099915,
      "learning_rate": 1.692451378969344e-05,
      "loss": 0.2812,
      "step": 3300
    },
    {
      "epoch": 0.3582504544968453,
      "grad_norm": 5.658361911773682,
      "learning_rate": 1.6869574772003078e-05,
      "loss": 0.2837,
      "step": 3350
    },
    {
      "epoch": 0.3635974762057534,
      "grad_norm": 11.032227516174316,
      "learning_rate": 1.6814635754312715e-05,
      "loss": 0.2803,
      "step": 3400
    },
    {
      "epoch": 0.36894449791466155,
      "grad_norm": 0.6362072825431824,
      "learning_rate": 1.6759696736622352e-05,
      "loss": 0.3305,
      "step": 3450
    },
    {
      "epoch": 0.37429151962356966,
      "grad_norm": 21.52455711364746,
      "learning_rate": 1.6704757718931986e-05,
      "loss": 0.2982,
      "step": 3500
    },
    {
      "epoch": 0.3796385413324778,
      "grad_norm": 1.0980523824691772,
      "learning_rate": 1.6649818701241623e-05,
      "loss": 0.3791,
      "step": 3550
    },
    {
      "epoch": 0.3849855630413859,
      "grad_norm": 8.063138961791992,
      "learning_rate": 1.659487968355126e-05,
      "loss": 0.3365,
      "step": 3600
    },
    {
      "epoch": 0.3903325847502941,
      "grad_norm": 4.476261138916016,
      "learning_rate": 1.6539940665860897e-05,
      "loss": 0.3162,
      "step": 3650
    },
    {
      "epoch": 0.39567960645920225,
      "grad_norm": 3.405261516571045,
      "learning_rate": 1.648500164817053e-05,
      "loss": 0.3437,
      "step": 3700
    },
    {
      "epoch": 0.40102662816811036,
      "grad_norm": 28.007524490356445,
      "learning_rate": 1.643006263048017e-05,
      "loss": 0.2625,
      "step": 3750
    },
    {
      "epoch": 0.4063736498770185,
      "grad_norm": 29.552804946899414,
      "learning_rate": 1.6375123612789806e-05,
      "loss": 0.2767,
      "step": 3800
    },
    {
      "epoch": 0.4117206715859266,
      "grad_norm": 8.315073013305664,
      "learning_rate": 1.6320184595099443e-05,
      "loss": 0.3488,
      "step": 3850
    },
    {
      "epoch": 0.4170676932948348,
      "grad_norm": 7.427602767944336,
      "learning_rate": 1.6265245577409076e-05,
      "loss": 0.2658,
      "step": 3900
    },
    {
      "epoch": 0.4224147150037429,
      "grad_norm": 11.256396293640137,
      "learning_rate": 1.6210306559718714e-05,
      "loss": 0.2853,
      "step": 3950
    },
    {
      "epoch": 0.42776173671265105,
      "grad_norm": 0.9796546697616577,
      "learning_rate": 1.615536754202835e-05,
      "loss": 0.3146,
      "step": 4000
    },
    {
      "epoch": 0.4331087584215592,
      "grad_norm": 1.437658667564392,
      "learning_rate": 1.6100428524337985e-05,
      "loss": 0.3722,
      "step": 4050
    },
    {
      "epoch": 0.4384557801304673,
      "grad_norm": 20.798364639282227,
      "learning_rate": 1.604548950664762e-05,
      "loss": 0.3447,
      "step": 4100
    },
    {
      "epoch": 0.4438028018393755,
      "grad_norm": 6.490728855133057,
      "learning_rate": 1.599055048895726e-05,
      "loss": 0.2549,
      "step": 4150
    },
    {
      "epoch": 0.4491498235482836,
      "grad_norm": 1.8283354043960571,
      "learning_rate": 1.5935611471266893e-05,
      "loss": 0.27,
      "step": 4200
    },
    {
      "epoch": 0.45449684525719175,
      "grad_norm": 6.500503063201904,
      "learning_rate": 1.588067245357653e-05,
      "loss": 0.2917,
      "step": 4250
    },
    {
      "epoch": 0.45984386696609986,
      "grad_norm": 2.4171767234802246,
      "learning_rate": 1.5825733435886167e-05,
      "loss": 0.2985,
      "step": 4300
    },
    {
      "epoch": 0.465190888675008,
      "grad_norm": 24.638322830200195,
      "learning_rate": 1.5770794418195804e-05,
      "loss": 0.2612,
      "step": 4350
    },
    {
      "epoch": 0.4705379103839162,
      "grad_norm": 8.932291984558105,
      "learning_rate": 1.571585540050544e-05,
      "loss": 0.398,
      "step": 4400
    },
    {
      "epoch": 0.4758849320928243,
      "grad_norm": 0.2542301118373871,
      "learning_rate": 1.566091638281508e-05,
      "loss": 0.2563,
      "step": 4450
    },
    {
      "epoch": 0.48123195380173245,
      "grad_norm": 1.436380386352539,
      "learning_rate": 1.5605977365124712e-05,
      "loss": 0.3337,
      "step": 4500
    },
    {
      "epoch": 0.48657897551064055,
      "grad_norm": 17.177778244018555,
      "learning_rate": 1.555103834743435e-05,
      "loss": 0.2824,
      "step": 4550
    },
    {
      "epoch": 0.4919259972195487,
      "grad_norm": 13.856968879699707,
      "learning_rate": 1.5496099329743986e-05,
      "loss": 0.2615,
      "step": 4600
    },
    {
      "epoch": 0.4972730189284568,
      "grad_norm": 0.3829154670238495,
      "learning_rate": 1.5441160312053624e-05,
      "loss": 0.2903,
      "step": 4650
    },
    {
      "epoch": 0.502620040637365,
      "grad_norm": 13.67843246459961,
      "learning_rate": 1.5386221294363257e-05,
      "loss": 0.3565,
      "step": 4700
    },
    {
      "epoch": 0.5079670623462731,
      "grad_norm": 7.976902961730957,
      "learning_rate": 1.5331282276672895e-05,
      "loss": 0.2293,
      "step": 4750
    },
    {
      "epoch": 0.5133140840551813,
      "grad_norm": 33.500099182128906,
      "learning_rate": 1.5276343258982532e-05,
      "loss": 0.2552,
      "step": 4800
    },
    {
      "epoch": 0.5186611057640894,
      "grad_norm": 29.769241333007812,
      "learning_rate": 1.5221404241292165e-05,
      "loss": 0.2855,
      "step": 4850
    },
    {
      "epoch": 0.5240081274729975,
      "grad_norm": 32.992671966552734,
      "learning_rate": 1.5166465223601803e-05,
      "loss": 0.2767,
      "step": 4900
    },
    {
      "epoch": 0.5293551491819056,
      "grad_norm": 5.020203113555908,
      "learning_rate": 1.511152620591144e-05,
      "loss": 0.2636,
      "step": 4950
    },
    {
      "epoch": 0.5347021708908138,
      "grad_norm": 4.678391933441162,
      "learning_rate": 1.5056587188221077e-05,
      "loss": 0.3073,
      "step": 5000
    },
    {
      "epoch": 0.540049192599722,
      "grad_norm": 18.76891326904297,
      "learning_rate": 1.500164817053071e-05,
      "loss": 0.2963,
      "step": 5050
    },
    {
      "epoch": 0.5453962143086301,
      "grad_norm": 33.79658126831055,
      "learning_rate": 1.4946709152840348e-05,
      "loss": 0.2597,
      "step": 5100
    },
    {
      "epoch": 0.5507432360175383,
      "grad_norm": 13.764065742492676,
      "learning_rate": 1.4891770135149985e-05,
      "loss": 0.3153,
      "step": 5150
    },
    {
      "epoch": 0.5560902577264464,
      "grad_norm": 1.0889666080474854,
      "learning_rate": 1.483683111745962e-05,
      "loss": 0.3012,
      "step": 5200
    },
    {
      "epoch": 0.5614372794353545,
      "grad_norm": 9.479805946350098,
      "learning_rate": 1.4781892099769258e-05,
      "loss": 0.3287,
      "step": 5250
    },
    {
      "epoch": 0.5667843011442626,
      "grad_norm": 2.6477463245391846,
      "learning_rate": 1.4726953082078895e-05,
      "loss": 0.2603,
      "step": 5300
    },
    {
      "epoch": 0.5721313228531708,
      "grad_norm": 7.694854736328125,
      "learning_rate": 1.4672014064388529e-05,
      "loss": 0.315,
      "step": 5350
    },
    {
      "epoch": 0.5774783445620789,
      "grad_norm": 17.506803512573242,
      "learning_rate": 1.4617075046698166e-05,
      "loss": 0.3297,
      "step": 5400
    },
    {
      "epoch": 0.582825366270987,
      "grad_norm": 12.999232292175293,
      "learning_rate": 1.4562136029007803e-05,
      "loss": 0.2736,
      "step": 5450
    },
    {
      "epoch": 0.5881723879798952,
      "grad_norm": 0.2751125991344452,
      "learning_rate": 1.450719701131744e-05,
      "loss": 0.3102,
      "step": 5500
    },
    {
      "epoch": 0.5935194096888033,
      "grad_norm": 6.569575786590576,
      "learning_rate": 1.4452257993627074e-05,
      "loss": 0.2638,
      "step": 5550
    },
    {
      "epoch": 0.5988664313977115,
      "grad_norm": 32.77351379394531,
      "learning_rate": 1.4397318975936711e-05,
      "loss": 0.3187,
      "step": 5600
    },
    {
      "epoch": 0.6042134531066196,
      "grad_norm": 23.572668075561523,
      "learning_rate": 1.4342379958246348e-05,
      "loss": 0.2158,
      "step": 5650
    },
    {
      "epoch": 0.6095604748155278,
      "grad_norm": 7.257338047027588,
      "learning_rate": 1.4287440940555984e-05,
      "loss": 0.3173,
      "step": 5700
    },
    {
      "epoch": 0.6149074965244359,
      "grad_norm": 4.207103729248047,
      "learning_rate": 1.423250192286562e-05,
      "loss": 0.2668,
      "step": 5750
    },
    {
      "epoch": 0.620254518233344,
      "grad_norm": 14.392342567443848,
      "learning_rate": 1.4177562905175258e-05,
      "loss": 0.2998,
      "step": 5800
    },
    {
      "epoch": 0.6256015399422522,
      "grad_norm": 14.726716995239258,
      "learning_rate": 1.4122623887484892e-05,
      "loss": 0.298,
      "step": 5850
    },
    {
      "epoch": 0.6309485616511603,
      "grad_norm": 53.96920394897461,
      "learning_rate": 1.4067684869794529e-05,
      "loss": 0.2913,
      "step": 5900
    },
    {
      "epoch": 0.6362955833600684,
      "grad_norm": 6.4491658210754395,
      "learning_rate": 1.4012745852104166e-05,
      "loss": 0.2828,
      "step": 5950
    },
    {
      "epoch": 0.6416426050689766,
      "grad_norm": 6.312446594238281,
      "learning_rate": 1.3957806834413803e-05,
      "loss": 0.2588,
      "step": 6000
    },
    {
      "epoch": 0.6469896267778847,
      "grad_norm": 0.16081200540065765,
      "learning_rate": 1.3902867816723437e-05,
      "loss": 0.2264,
      "step": 6050
    },
    {
      "epoch": 0.6523366484867928,
      "grad_norm": 14.364632606506348,
      "learning_rate": 1.3847928799033074e-05,
      "loss": 0.2887,
      "step": 6100
    },
    {
      "epoch": 0.657683670195701,
      "grad_norm": 28.246402740478516,
      "learning_rate": 1.3792989781342711e-05,
      "loss": 0.3337,
      "step": 6150
    },
    {
      "epoch": 0.6630306919046092,
      "grad_norm": 35.95964813232422,
      "learning_rate": 1.3738050763652347e-05,
      "loss": 0.264,
      "step": 6200
    },
    {
      "epoch": 0.6683777136135173,
      "grad_norm": 0.8535335659980774,
      "learning_rate": 1.3683111745961984e-05,
      "loss": 0.3094,
      "step": 6250
    },
    {
      "epoch": 0.6737247353224254,
      "grad_norm": 0.6089958548545837,
      "learning_rate": 1.3628172728271621e-05,
      "loss": 0.2404,
      "step": 6300
    },
    {
      "epoch": 0.6790717570313336,
      "grad_norm": 10.035326957702637,
      "learning_rate": 1.3573233710581255e-05,
      "loss": 0.2482,
      "step": 6350
    },
    {
      "epoch": 0.6844187787402417,
      "grad_norm": 0.1748385727405548,
      "learning_rate": 1.3518294692890892e-05,
      "loss": 0.2469,
      "step": 6400
    },
    {
      "epoch": 0.6897658004491498,
      "grad_norm": 2.555701494216919,
      "learning_rate": 1.3463355675200529e-05,
      "loss": 0.3264,
      "step": 6450
    },
    {
      "epoch": 0.6951128221580579,
      "grad_norm": 3.191561222076416,
      "learning_rate": 1.3408416657510165e-05,
      "loss": 0.2879,
      "step": 6500
    },
    {
      "epoch": 0.7004598438669661,
      "grad_norm": 0.18540339171886444,
      "learning_rate": 1.33534776398198e-05,
      "loss": 0.2912,
      "step": 6550
    },
    {
      "epoch": 0.7058068655758742,
      "grad_norm": 15.401322364807129,
      "learning_rate": 1.3298538622129437e-05,
      "loss": 0.3142,
      "step": 6600
    },
    {
      "epoch": 0.7111538872847823,
      "grad_norm": 0.38978907465934753,
      "learning_rate": 1.3243599604439074e-05,
      "loss": 0.2514,
      "step": 6650
    },
    {
      "epoch": 0.7165009089936906,
      "grad_norm": 18.929290771484375,
      "learning_rate": 1.318866058674871e-05,
      "loss": 0.258,
      "step": 6700
    },
    {
      "epoch": 0.7218479307025987,
      "grad_norm": 2.1079561710357666,
      "learning_rate": 1.3133721569058347e-05,
      "loss": 0.3163,
      "step": 6750
    },
    {
      "epoch": 0.7271949524115068,
      "grad_norm": 0.7695014476776123,
      "learning_rate": 1.3078782551367984e-05,
      "loss": 0.2415,
      "step": 6800
    },
    {
      "epoch": 0.7325419741204149,
      "grad_norm": 0.27859634160995483,
      "learning_rate": 1.3023843533677618e-05,
      "loss": 0.2776,
      "step": 6850
    },
    {
      "epoch": 0.7378889958293231,
      "grad_norm": 40.21552658081055,
      "learning_rate": 1.2968904515987255e-05,
      "loss": 0.2457,
      "step": 6900
    },
    {
      "epoch": 0.7432360175382312,
      "grad_norm": 14.42630386352539,
      "learning_rate": 1.2913965498296892e-05,
      "loss": 0.2492,
      "step": 6950
    },
    {
      "epoch": 0.7485830392471393,
      "grad_norm": 0.38756653666496277,
      "learning_rate": 1.2859026480606528e-05,
      "loss": 0.3358,
      "step": 7000
    },
    {
      "epoch": 0.7539300609560475,
      "grad_norm": 12.004216194152832,
      "learning_rate": 1.2804087462916163e-05,
      "loss": 0.2471,
      "step": 7050
    },
    {
      "epoch": 0.7592770826649556,
      "grad_norm": 1.8490909337997437,
      "learning_rate": 1.27491484452258e-05,
      "loss": 0.2879,
      "step": 7100
    },
    {
      "epoch": 0.7646241043738637,
      "grad_norm": 10.53575325012207,
      "learning_rate": 1.2694209427535437e-05,
      "loss": 0.2866,
      "step": 7150
    },
    {
      "epoch": 0.7699711260827719,
      "grad_norm": 8.593047142028809,
      "learning_rate": 1.2639270409845073e-05,
      "loss": 0.2343,
      "step": 7200
    },
    {
      "epoch": 0.7753181477916801,
      "grad_norm": 0.4566565752029419,
      "learning_rate": 1.258433139215471e-05,
      "loss": 0.2337,
      "step": 7250
    },
    {
      "epoch": 0.7806651695005882,
      "grad_norm": 24.75602149963379,
      "learning_rate": 1.2529392374464347e-05,
      "loss": 0.3111,
      "step": 7300
    },
    {
      "epoch": 0.7860121912094963,
      "grad_norm": 6.254673480987549,
      "learning_rate": 1.2474453356773981e-05,
      "loss": 0.2926,
      "step": 7350
    },
    {
      "epoch": 0.7913592129184045,
      "grad_norm": 15.585022926330566,
      "learning_rate": 1.2419514339083618e-05,
      "loss": 0.2769,
      "step": 7400
    },
    {
      "epoch": 0.7967062346273126,
      "grad_norm": 19.897245407104492,
      "learning_rate": 1.2364575321393255e-05,
      "loss": 0.2174,
      "step": 7450
    },
    {
      "epoch": 0.8020532563362207,
      "grad_norm": 13.387712478637695,
      "learning_rate": 1.2309636303702889e-05,
      "loss": 0.2375,
      "step": 7500
    },
    {
      "epoch": 0.8074002780451288,
      "grad_norm": 0.45848706364631653,
      "learning_rate": 1.2254697286012526e-05,
      "loss": 0.3134,
      "step": 7550
    },
    {
      "epoch": 0.812747299754037,
      "grad_norm": 3.112612247467041,
      "learning_rate": 1.2199758268322163e-05,
      "loss": 0.2163,
      "step": 7600
    },
    {
      "epoch": 0.8180943214629451,
      "grad_norm": 0.902765691280365,
      "learning_rate": 1.21448192506318e-05,
      "loss": 0.3259,
      "step": 7650
    },
    {
      "epoch": 0.8234413431718532,
      "grad_norm": 0.7532958984375,
      "learning_rate": 1.2089880232941436e-05,
      "loss": 0.2751,
      "step": 7700
    },
    {
      "epoch": 0.8287883648807615,
      "grad_norm": 12.222504615783691,
      "learning_rate": 1.2034941215251073e-05,
      "loss": 0.2413,
      "step": 7750
    },
    {
      "epoch": 0.8341353865896696,
      "grad_norm": 28.999284744262695,
      "learning_rate": 1.198000219756071e-05,
      "loss": 0.2631,
      "step": 7800
    },
    {
      "epoch": 0.8394824082985777,
      "grad_norm": 35.8948860168457,
      "learning_rate": 1.1925063179870344e-05,
      "loss": 0.2692,
      "step": 7850
    },
    {
      "epoch": 0.8448294300074858,
      "grad_norm": 57.96863555908203,
      "learning_rate": 1.1870124162179981e-05,
      "loss": 0.2837,
      "step": 7900
    },
    {
      "epoch": 0.850176451716394,
      "grad_norm": 13.253071784973145,
      "learning_rate": 1.1815185144489618e-05,
      "loss": 0.2741,
      "step": 7950
    },
    {
      "epoch": 0.8555234734253021,
      "grad_norm": 4.508538246154785,
      "learning_rate": 1.1760246126799252e-05,
      "loss": 0.2486,
      "step": 8000
    },
    {
      "epoch": 0.8608704951342102,
      "grad_norm": 9.999918937683105,
      "learning_rate": 1.170530710910889e-05,
      "loss": 0.2083,
      "step": 8050
    },
    {
      "epoch": 0.8662175168431184,
      "grad_norm": 17.0297794342041,
      "learning_rate": 1.1650368091418526e-05,
      "loss": 0.2295,
      "step": 8100
    },
    {
      "epoch": 0.8715645385520265,
      "grad_norm": 39.144248962402344,
      "learning_rate": 1.1595429073728162e-05,
      "loss": 0.2475,
      "step": 8150
    },
    {
      "epoch": 0.8769115602609346,
      "grad_norm": 25.9428653717041,
      "learning_rate": 1.1540490056037799e-05,
      "loss": 0.2365,
      "step": 8200
    },
    {
      "epoch": 0.8822585819698427,
      "grad_norm": 40.980491638183594,
      "learning_rate": 1.1485551038347436e-05,
      "loss": 0.2837,
      "step": 8250
    },
    {
      "epoch": 0.887605603678751,
      "grad_norm": 13.998931884765625,
      "learning_rate": 1.1430612020657073e-05,
      "loss": 0.2676,
      "step": 8300
    },
    {
      "epoch": 0.8929526253876591,
      "grad_norm": 7.160714626312256,
      "learning_rate": 1.1375673002966707e-05,
      "loss": 0.2168,
      "step": 8350
    },
    {
      "epoch": 0.8982996470965672,
      "grad_norm": 14.453361511230469,
      "learning_rate": 1.1320733985276344e-05,
      "loss": 0.3017,
      "step": 8400
    },
    {
      "epoch": 0.9036466688054754,
      "grad_norm": 0.9022241830825806,
      "learning_rate": 1.1265794967585981e-05,
      "loss": 0.2132,
      "step": 8450
    },
    {
      "epoch": 0.9089936905143835,
      "grad_norm": 21.806177139282227,
      "learning_rate": 1.1210855949895615e-05,
      "loss": 0.2017,
      "step": 8500
    },
    {
      "epoch": 0.9143407122232916,
      "grad_norm": 23.016714096069336,
      "learning_rate": 1.1155916932205252e-05,
      "loss": 0.2813,
      "step": 8550
    },
    {
      "epoch": 0.9196877339321997,
      "grad_norm": 3.0114128589630127,
      "learning_rate": 1.110097791451489e-05,
      "loss": 0.2832,
      "step": 8600
    },
    {
      "epoch": 0.9250347556411079,
      "grad_norm": 0.20032203197479248,
      "learning_rate": 1.1046038896824525e-05,
      "loss": 0.2275,
      "step": 8650
    },
    {
      "epoch": 0.930381777350016,
      "grad_norm": 34.2493896484375,
      "learning_rate": 1.0991099879134162e-05,
      "loss": 0.2137,
      "step": 8700
    },
    {
      "epoch": 0.9357287990589241,
      "grad_norm": 30.6427059173584,
      "learning_rate": 1.09361608614438e-05,
      "loss": 0.2523,
      "step": 8750
    },
    {
      "epoch": 0.9410758207678324,
      "grad_norm": 0.33596739172935486,
      "learning_rate": 1.0881221843753435e-05,
      "loss": 0.226,
      "step": 8800
    },
    {
      "epoch": 0.9464228424767405,
      "grad_norm": 24.635095596313477,
      "learning_rate": 1.082628282606307e-05,
      "loss": 0.263,
      "step": 8850
    },
    {
      "epoch": 0.9517698641856486,
      "grad_norm": 0.4012242555618286,
      "learning_rate": 1.0771343808372707e-05,
      "loss": 0.2835,
      "step": 8900
    },
    {
      "epoch": 0.9571168858945567,
      "grad_norm": 7.348691463470459,
      "learning_rate": 1.0716404790682345e-05,
      "loss": 0.2584,
      "step": 8950
    },
    {
      "epoch": 0.9624639076034649,
      "grad_norm": 2.6937384605407715,
      "learning_rate": 1.0661465772991978e-05,
      "loss": 0.2502,
      "step": 9000
    },
    {
      "epoch": 0.967810929312373,
      "grad_norm": 19.654991149902344,
      "learning_rate": 1.0606526755301615e-05,
      "loss": 0.2579,
      "step": 9050
    },
    {
      "epoch": 0.9731579510212811,
      "grad_norm": 4.129249095916748,
      "learning_rate": 1.0551587737611253e-05,
      "loss": 0.2639,
      "step": 9100
    },
    {
      "epoch": 0.9785049727301893,
      "grad_norm": 0.20282022655010223,
      "learning_rate": 1.0496648719920888e-05,
      "loss": 0.2372,
      "step": 9150
    },
    {
      "epoch": 0.9838519944390974,
      "grad_norm": 3.9283649921417236,
      "learning_rate": 1.0441709702230525e-05,
      "loss": 0.3096,
      "step": 9200
    },
    {
      "epoch": 0.9891990161480055,
      "grad_norm": 1.3598666191101074,
      "learning_rate": 1.0386770684540162e-05,
      "loss": 0.298,
      "step": 9250
    },
    {
      "epoch": 0.9945460378569136,
      "grad_norm": 28.32166862487793,
      "learning_rate": 1.0331831666849798e-05,
      "loss": 0.2407,
      "step": 9300
    },
    {
      "epoch": 0.9998930595658219,
      "grad_norm": 0.7888848781585693,
      "learning_rate": 1.0276892649159433e-05,
      "loss": 0.2429,
      "step": 9350
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9325740562506684,
      "eval_f1": 0.9410224030681447,
      "eval_loss": 0.21732069551944733,
      "eval_precision": 0.9407144193005423,
      "eval_recall": 0.941330588565547,
      "eval_runtime": 1852.0374,
      "eval_samples_per_second": 10.098,
      "eval_steps_per_second": 0.316,
      "step": 9351
    }
  ],
  "logging_steps": 50,
  "max_steps": 18702,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4954744345629696.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
