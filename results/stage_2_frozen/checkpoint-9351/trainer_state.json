{
  "best_global_step": 9351,
  "best_metric": 0.19673468172550201,
  "best_model_checkpoint": "results\\stage_2_frozen\\checkpoint-9351",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 9351,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005347021708908138,
      "grad_norm": 0.05598467215895653,
      "learning_rate": 9.800000000000001e-07,
      "loss": 0.0555,
      "step": 50
    },
    {
      "epoch": 0.010694043417816277,
      "grad_norm": 2.347062587738037,
      "learning_rate": 1.98e-06,
      "loss": 0.183,
      "step": 100
    },
    {
      "epoch": 0.016041065126724416,
      "grad_norm": 0.07010240852832794,
      "learning_rate": 2.9800000000000003e-06,
      "loss": 0.1368,
      "step": 150
    },
    {
      "epoch": 0.021388086835632553,
      "grad_norm": 0.06692837923765182,
      "learning_rate": 3.980000000000001e-06,
      "loss": 0.1299,
      "step": 200
    },
    {
      "epoch": 0.02673510854454069,
      "grad_norm": 0.16110993921756744,
      "learning_rate": 4.980000000000001e-06,
      "loss": 0.1638,
      "step": 250
    },
    {
      "epoch": 0.03208213025344883,
      "grad_norm": 0.04252134636044502,
      "learning_rate": 5.98e-06,
      "loss": 0.1329,
      "step": 300
    },
    {
      "epoch": 0.037429151962356966,
      "grad_norm": 0.0782916396856308,
      "learning_rate": 6.98e-06,
      "loss": 0.0621,
      "step": 350
    },
    {
      "epoch": 0.04277617367126511,
      "grad_norm": 0.09947897493839264,
      "learning_rate": 7.980000000000002e-06,
      "loss": 0.091,
      "step": 400
    },
    {
      "epoch": 0.04812319538017324,
      "grad_norm": 2.035266399383545,
      "learning_rate": 8.98e-06,
      "loss": 0.0481,
      "step": 450
    },
    {
      "epoch": 0.05347021708908138,
      "grad_norm": 0.04915938898921013,
      "learning_rate": 9.980000000000001e-06,
      "loss": 0.0625,
      "step": 500
    },
    {
      "epoch": 0.05881723879798952,
      "grad_norm": 1.326874017715454,
      "learning_rate": 9.944639023839115e-06,
      "loss": 0.1608,
      "step": 550
    },
    {
      "epoch": 0.06416426050689766,
      "grad_norm": 0.06208433210849762,
      "learning_rate": 9.888148231838212e-06,
      "loss": 0.0888,
      "step": 600
    },
    {
      "epoch": 0.0695112822158058,
      "grad_norm": 0.03674604371190071,
      "learning_rate": 9.831657439837308e-06,
      "loss": 0.0384,
      "step": 650
    },
    {
      "epoch": 0.07485830392471393,
      "grad_norm": 0.08017096668481827,
      "learning_rate": 9.775166647836403e-06,
      "loss": 0.0584,
      "step": 700
    },
    {
      "epoch": 0.08020532563362208,
      "grad_norm": 0.10631115734577179,
      "learning_rate": 9.7186758558355e-06,
      "loss": 0.0787,
      "step": 750
    },
    {
      "epoch": 0.08555234734253021,
      "grad_norm": 0.0925745815038681,
      "learning_rate": 9.662185063834596e-06,
      "loss": 0.0711,
      "step": 800
    },
    {
      "epoch": 0.09089936905143835,
      "grad_norm": 0.08418727666139603,
      "learning_rate": 9.605694271833692e-06,
      "loss": 0.1174,
      "step": 850
    },
    {
      "epoch": 0.09624639076034648,
      "grad_norm": 0.06569160521030426,
      "learning_rate": 9.549203479832789e-06,
      "loss": 0.0716,
      "step": 900
    },
    {
      "epoch": 0.10159341246925463,
      "grad_norm": 0.05165047571063042,
      "learning_rate": 9.492712687831884e-06,
      "loss": 0.0998,
      "step": 950
    },
    {
      "epoch": 0.10694043417816276,
      "grad_norm": 0.0662836879491806,
      "learning_rate": 9.43622189583098e-06,
      "loss": 0.0514,
      "step": 1000
    },
    {
      "epoch": 0.1122874558870709,
      "grad_norm": 0.14951127767562866,
      "learning_rate": 9.379731103830077e-06,
      "loss": 0.1172,
      "step": 1050
    },
    {
      "epoch": 0.11763447759597905,
      "grad_norm": 0.0756375640630722,
      "learning_rate": 9.323240311829173e-06,
      "loss": 0.0735,
      "step": 1100
    },
    {
      "epoch": 0.12298149930488718,
      "grad_norm": 0.1620796173810959,
      "learning_rate": 9.266749519828268e-06,
      "loss": 0.1197,
      "step": 1150
    },
    {
      "epoch": 0.12832852101379533,
      "grad_norm": 0.15101118385791779,
      "learning_rate": 9.210258727827365e-06,
      "loss": 0.0808,
      "step": 1200
    },
    {
      "epoch": 0.13367554272270346,
      "grad_norm": 0.15132038295269012,
      "learning_rate": 9.15376793582646e-06,
      "loss": 0.0658,
      "step": 1250
    },
    {
      "epoch": 0.1390225644316116,
      "grad_norm": 2.9075684547424316,
      "learning_rate": 9.097277143825556e-06,
      "loss": 0.0909,
      "step": 1300
    },
    {
      "epoch": 0.14436958614051973,
      "grad_norm": 0.2704956829547882,
      "learning_rate": 9.040786351824654e-06,
      "loss": 0.1158,
      "step": 1350
    },
    {
      "epoch": 0.14971660784942786,
      "grad_norm": 0.13627374172210693,
      "learning_rate": 8.984295559823749e-06,
      "loss": 0.0923,
      "step": 1400
    },
    {
      "epoch": 0.155063629558336,
      "grad_norm": 0.14323917031288147,
      "learning_rate": 8.927804767822845e-06,
      "loss": 0.0829,
      "step": 1450
    },
    {
      "epoch": 0.16041065126724416,
      "grad_norm": 0.20600295066833496,
      "learning_rate": 8.871313975821942e-06,
      "loss": 0.0582,
      "step": 1500
    },
    {
      "epoch": 0.1657576729761523,
      "grad_norm": 0.07647328078746796,
      "learning_rate": 8.814823183821037e-06,
      "loss": 0.0566,
      "step": 1550
    },
    {
      "epoch": 0.17110469468506043,
      "grad_norm": 1.1560015678405762,
      "learning_rate": 8.758332391820133e-06,
      "loss": 0.0649,
      "step": 1600
    },
    {
      "epoch": 0.17645171639396856,
      "grad_norm": 0.04484926536679268,
      "learning_rate": 8.70184159981923e-06,
      "loss": 0.0798,
      "step": 1650
    },
    {
      "epoch": 0.1817987381028767,
      "grad_norm": 0.05961659178137779,
      "learning_rate": 8.645350807818327e-06,
      "loss": 0.0945,
      "step": 1700
    },
    {
      "epoch": 0.18714575981178483,
      "grad_norm": 0.05911488085985184,
      "learning_rate": 8.588860015817423e-06,
      "loss": 0.055,
      "step": 1750
    },
    {
      "epoch": 0.19249278152069296,
      "grad_norm": 0.026050087064504623,
      "learning_rate": 8.532369223816518e-06,
      "loss": 0.0522,
      "step": 1800
    },
    {
      "epoch": 0.19783980322960112,
      "grad_norm": 0.1437348574399948,
      "learning_rate": 8.475878431815615e-06,
      "loss": 0.0613,
      "step": 1850
    },
    {
      "epoch": 0.20318682493850926,
      "grad_norm": 0.15748274326324463,
      "learning_rate": 8.419387639814711e-06,
      "loss": 0.0337,
      "step": 1900
    },
    {
      "epoch": 0.2085338466474174,
      "grad_norm": 0.06569243222475052,
      "learning_rate": 8.362896847813806e-06,
      "loss": 0.0691,
      "step": 1950
    },
    {
      "epoch": 0.21388086835632553,
      "grad_norm": 0.053016699850559235,
      "learning_rate": 8.306406055812904e-06,
      "loss": 0.0418,
      "step": 2000
    },
    {
      "epoch": 0.21922789006523366,
      "grad_norm": 1.2743067741394043,
      "learning_rate": 8.249915263812e-06,
      "loss": 0.0773,
      "step": 2050
    },
    {
      "epoch": 0.2245749117741418,
      "grad_norm": 1.2508392333984375,
      "learning_rate": 8.193424471811095e-06,
      "loss": 0.0363,
      "step": 2100
    },
    {
      "epoch": 0.22992193348304993,
      "grad_norm": 0.04829702153801918,
      "learning_rate": 8.136933679810192e-06,
      "loss": 0.0781,
      "step": 2150
    },
    {
      "epoch": 0.2352689551919581,
      "grad_norm": 0.10164009034633636,
      "learning_rate": 8.080442887809287e-06,
      "loss": 0.0646,
      "step": 2200
    },
    {
      "epoch": 0.24061597690086622,
      "grad_norm": 0.28127017617225647,
      "learning_rate": 8.023952095808385e-06,
      "loss": 0.062,
      "step": 2250
    },
    {
      "epoch": 0.24596299860977436,
      "grad_norm": 0.05453285574913025,
      "learning_rate": 7.96746130380748e-06,
      "loss": 0.0345,
      "step": 2300
    },
    {
      "epoch": 0.2513100203186825,
      "grad_norm": 0.12445459514856339,
      "learning_rate": 7.910970511806576e-06,
      "loss": 0.0917,
      "step": 2350
    },
    {
      "epoch": 0.25665704202759065,
      "grad_norm": 0.02591046690940857,
      "learning_rate": 7.854479719805673e-06,
      "loss": 0.0562,
      "step": 2400
    },
    {
      "epoch": 0.26200406373649876,
      "grad_norm": 0.0780009999871254,
      "learning_rate": 7.797988927804768e-06,
      "loss": 0.0493,
      "step": 2450
    },
    {
      "epoch": 0.2673510854454069,
      "grad_norm": 1.7477247714996338,
      "learning_rate": 7.741498135803864e-06,
      "loss": 0.111,
      "step": 2500
    },
    {
      "epoch": 0.27269810715431503,
      "grad_norm": 0.13433197140693665,
      "learning_rate": 7.685007343802961e-06,
      "loss": 0.043,
      "step": 2550
    },
    {
      "epoch": 0.2780451288632232,
      "grad_norm": 0.06376621127128601,
      "learning_rate": 7.628516551802057e-06,
      "loss": 0.0592,
      "step": 2600
    },
    {
      "epoch": 0.2833921505721313,
      "grad_norm": 0.06328293681144714,
      "learning_rate": 7.572025759801153e-06,
      "loss": 0.0913,
      "step": 2650
    },
    {
      "epoch": 0.28873917228103946,
      "grad_norm": 0.1943466067314148,
      "learning_rate": 7.5155349678002485e-06,
      "loss": 0.0434,
      "step": 2700
    },
    {
      "epoch": 0.2940861939899476,
      "grad_norm": 0.04986308515071869,
      "learning_rate": 7.459044175799345e-06,
      "loss": 0.1272,
      "step": 2750
    },
    {
      "epoch": 0.2994332156988557,
      "grad_norm": 0.1004866436123848,
      "learning_rate": 7.402553383798441e-06,
      "loss": 0.0357,
      "step": 2800
    },
    {
      "epoch": 0.3047802374077639,
      "grad_norm": 0.10764413326978683,
      "learning_rate": 7.3460625917975385e-06,
      "loss": 0.0561,
      "step": 2850
    },
    {
      "epoch": 0.310127259116672,
      "grad_norm": 0.10697188228368759,
      "learning_rate": 7.289571799796634e-06,
      "loss": 0.047,
      "step": 2900
    },
    {
      "epoch": 0.31547428082558016,
      "grad_norm": 0.3995804786682129,
      "learning_rate": 7.23308100779573e-06,
      "loss": 0.0938,
      "step": 2950
    },
    {
      "epoch": 0.3208213025344883,
      "grad_norm": 0.114507295191288,
      "learning_rate": 7.176590215794827e-06,
      "loss": 0.0733,
      "step": 3000
    },
    {
      "epoch": 0.3261683242433964,
      "grad_norm": 2.926046133041382,
      "learning_rate": 7.120099423793922e-06,
      "loss": 0.069,
      "step": 3050
    },
    {
      "epoch": 0.3315153459523046,
      "grad_norm": 0.06501748412847519,
      "learning_rate": 7.063608631793019e-06,
      "loss": 0.0587,
      "step": 3100
    },
    {
      "epoch": 0.3368623676612127,
      "grad_norm": 0.05366974323987961,
      "learning_rate": 7.007117839792115e-06,
      "loss": 0.1196,
      "step": 3150
    },
    {
      "epoch": 0.34220938937012085,
      "grad_norm": 0.07519976794719696,
      "learning_rate": 6.9506270477912105e-06,
      "loss": 0.0433,
      "step": 3200
    },
    {
      "epoch": 0.34755641107902896,
      "grad_norm": 0.27006030082702637,
      "learning_rate": 6.894136255790307e-06,
      "loss": 0.0399,
      "step": 3250
    },
    {
      "epoch": 0.3529034327879371,
      "grad_norm": 0.015162249095737934,
      "learning_rate": 6.837645463789403e-06,
      "loss": 0.05,
      "step": 3300
    },
    {
      "epoch": 0.3582504544968453,
      "grad_norm": 0.07145047932863235,
      "learning_rate": 6.781154671788499e-06,
      "loss": 0.0823,
      "step": 3350
    },
    {
      "epoch": 0.3635974762057534,
      "grad_norm": 2.3602490425109863,
      "learning_rate": 6.724663879787595e-06,
      "loss": 0.0532,
      "step": 3400
    },
    {
      "epoch": 0.36894449791466155,
      "grad_norm": 0.04287089407444,
      "learning_rate": 6.6681730877866914e-06,
      "loss": 0.0414,
      "step": 3450
    },
    {
      "epoch": 0.37429151962356966,
      "grad_norm": 0.12684266269207,
      "learning_rate": 6.611682295785787e-06,
      "loss": 0.058,
      "step": 3500
    },
    {
      "epoch": 0.3796385413324778,
      "grad_norm": 0.036888547241687775,
      "learning_rate": 6.555191503784883e-06,
      "loss": 0.0722,
      "step": 3550
    },
    {
      "epoch": 0.3849855630413859,
      "grad_norm": 0.038072727620601654,
      "learning_rate": 6.49870071178398e-06,
      "loss": 0.0785,
      "step": 3600
    },
    {
      "epoch": 0.3903325847502941,
      "grad_norm": 0.06570732593536377,
      "learning_rate": 6.442209919783076e-06,
      "loss": 0.0648,
      "step": 3650
    },
    {
      "epoch": 0.39567960645920225,
      "grad_norm": 0.0223485566675663,
      "learning_rate": 6.3857191277821715e-06,
      "loss": 0.043,
      "step": 3700
    },
    {
      "epoch": 0.40102662816811036,
      "grad_norm": 0.02772166021168232,
      "learning_rate": 6.329228335781268e-06,
      "loss": 0.0293,
      "step": 3750
    },
    {
      "epoch": 0.4063736498770185,
      "grad_norm": 0.07711639255285263,
      "learning_rate": 6.272737543780364e-06,
      "loss": 0.0544,
      "step": 3800
    },
    {
      "epoch": 0.4117206715859266,
      "grad_norm": 0.10237893462181091,
      "learning_rate": 6.21624675177946e-06,
      "loss": 0.0577,
      "step": 3850
    },
    {
      "epoch": 0.4170676932948348,
      "grad_norm": 0.03717928007245064,
      "learning_rate": 6.159755959778556e-06,
      "loss": 0.0694,
      "step": 3900
    },
    {
      "epoch": 0.4224147150037429,
      "grad_norm": 0.058701153844594955,
      "learning_rate": 6.1032651677776525e-06,
      "loss": 0.0656,
      "step": 3950
    },
    {
      "epoch": 0.42776173671265105,
      "grad_norm": 0.029801886528730392,
      "learning_rate": 6.04677437577675e-06,
      "loss": 0.0518,
      "step": 4000
    },
    {
      "epoch": 0.4331087584215592,
      "grad_norm": 0.0768151730298996,
      "learning_rate": 5.990283583775845e-06,
      "loss": 0.1338,
      "step": 4050
    },
    {
      "epoch": 0.4384557801304673,
      "grad_norm": 1.696579098701477,
      "learning_rate": 5.933792791774942e-06,
      "loss": 0.1208,
      "step": 4100
    },
    {
      "epoch": 0.4438028018393755,
      "grad_norm": 0.06937266886234283,
      "learning_rate": 5.877301999774038e-06,
      "loss": 0.0519,
      "step": 4150
    },
    {
      "epoch": 0.4491498235482836,
      "grad_norm": 0.027117455378174782,
      "learning_rate": 5.8208112077731335e-06,
      "loss": 0.0559,
      "step": 4200
    },
    {
      "epoch": 0.45449684525719175,
      "grad_norm": 0.06212018430233002,
      "learning_rate": 5.76432041577223e-06,
      "loss": 0.0443,
      "step": 4250
    },
    {
      "epoch": 0.45984386696609986,
      "grad_norm": 0.06596510112285614,
      "learning_rate": 5.707829623771326e-06,
      "loss": 0.0586,
      "step": 4300
    },
    {
      "epoch": 0.465190888675008,
      "grad_norm": 3.6043903827667236,
      "learning_rate": 5.651338831770422e-06,
      "loss": 0.0461,
      "step": 4350
    },
    {
      "epoch": 0.4705379103839162,
      "grad_norm": 0.01844722218811512,
      "learning_rate": 5.594848039769518e-06,
      "loss": 0.0581,
      "step": 4400
    },
    {
      "epoch": 0.4758849320928243,
      "grad_norm": 0.026062576100230217,
      "learning_rate": 5.5383572477686144e-06,
      "loss": 0.0356,
      "step": 4450
    },
    {
      "epoch": 0.48123195380173245,
      "grad_norm": 0.04698403924703598,
      "learning_rate": 5.48186645576771e-06,
      "loss": 0.0468,
      "step": 4500
    },
    {
      "epoch": 0.48657897551064055,
      "grad_norm": 0.04579377919435501,
      "learning_rate": 5.425375663766806e-06,
      "loss": 0.0271,
      "step": 4550
    },
    {
      "epoch": 0.4919259972195487,
      "grad_norm": 0.10347750782966614,
      "learning_rate": 5.368884871765903e-06,
      "loss": 0.0417,
      "step": 4600
    },
    {
      "epoch": 0.4972730189284568,
      "grad_norm": 0.02974030189216137,
      "learning_rate": 5.312394079764999e-06,
      "loss": 0.0469,
      "step": 4650
    },
    {
      "epoch": 0.502620040637365,
      "grad_norm": 0.05998989939689636,
      "learning_rate": 5.2559032877640946e-06,
      "loss": 0.0507,
      "step": 4700
    },
    {
      "epoch": 0.5079670623462731,
      "grad_norm": 0.09688118100166321,
      "learning_rate": 5.199412495763191e-06,
      "loss": 0.0533,
      "step": 4750
    },
    {
      "epoch": 0.5133140840551813,
      "grad_norm": 0.13743101060390472,
      "learning_rate": 5.142921703762287e-06,
      "loss": 0.0297,
      "step": 4800
    },
    {
      "epoch": 0.5186611057640894,
      "grad_norm": 3.1351191997528076,
      "learning_rate": 5.086430911761383e-06,
      "loss": 0.0648,
      "step": 4850
    },
    {
      "epoch": 0.5240081274729975,
      "grad_norm": 0.25410324335098267,
      "learning_rate": 5.029940119760479e-06,
      "loss": 0.0851,
      "step": 4900
    },
    {
      "epoch": 0.5293551491819056,
      "grad_norm": 0.21718718111515045,
      "learning_rate": 4.9734493277595755e-06,
      "loss": 0.0342,
      "step": 4950
    },
    {
      "epoch": 0.5347021708908138,
      "grad_norm": 0.15944278240203857,
      "learning_rate": 4.916958535758672e-06,
      "loss": 0.0339,
      "step": 5000
    },
    {
      "epoch": 0.540049192599722,
      "grad_norm": 0.04869776591658592,
      "learning_rate": 4.860467743757768e-06,
      "loss": 0.1061,
      "step": 5050
    },
    {
      "epoch": 0.5453962143086301,
      "grad_norm": 0.7265623211860657,
      "learning_rate": 4.803976951756864e-06,
      "loss": 0.0857,
      "step": 5100
    },
    {
      "epoch": 0.5507432360175383,
      "grad_norm": 0.09596727043390274,
      "learning_rate": 4.74748615975596e-06,
      "loss": 0.0517,
      "step": 5150
    },
    {
      "epoch": 0.5560902577264464,
      "grad_norm": 0.04198465868830681,
      "learning_rate": 4.6909953677550565e-06,
      "loss": 0.0703,
      "step": 5200
    },
    {
      "epoch": 0.5614372794353545,
      "grad_norm": 0.014603912830352783,
      "learning_rate": 4.634504575754152e-06,
      "loss": 0.046,
      "step": 5250
    },
    {
      "epoch": 0.5667843011442626,
      "grad_norm": 0.14308609068393707,
      "learning_rate": 4.578013783753248e-06,
      "loss": 0.0272,
      "step": 5300
    },
    {
      "epoch": 0.5721313228531708,
      "grad_norm": 0.04306778684258461,
      "learning_rate": 4.521522991752345e-06,
      "loss": 0.063,
      "step": 5350
    },
    {
      "epoch": 0.5774783445620789,
      "grad_norm": 0.04729771986603737,
      "learning_rate": 4.46503219975144e-06,
      "loss": 0.0969,
      "step": 5400
    },
    {
      "epoch": 0.582825366270987,
      "grad_norm": 0.03349500522017479,
      "learning_rate": 4.4085414077505374e-06,
      "loss": 0.0544,
      "step": 5450
    },
    {
      "epoch": 0.5881723879798952,
      "grad_norm": 0.045786499977111816,
      "learning_rate": 4.352050615749634e-06,
      "loss": 0.0577,
      "step": 5500
    },
    {
      "epoch": 0.5935194096888033,
      "grad_norm": 2.6448404788970947,
      "learning_rate": 4.295559823748729e-06,
      "loss": 0.0981,
      "step": 5550
    },
    {
      "epoch": 0.5988664313977115,
      "grad_norm": 0.09760042279958725,
      "learning_rate": 4.239069031747826e-06,
      "loss": 0.0424,
      "step": 5600
    },
    {
      "epoch": 0.6042134531066196,
      "grad_norm": 0.09371244162321091,
      "learning_rate": 4.182578239746922e-06,
      "loss": 0.0477,
      "step": 5650
    },
    {
      "epoch": 0.6095604748155278,
      "grad_norm": 0.03973529487848282,
      "learning_rate": 4.1260874477460176e-06,
      "loss": 0.0529,
      "step": 5700
    },
    {
      "epoch": 0.6149074965244359,
      "grad_norm": 0.015924982726573944,
      "learning_rate": 4.069596655745114e-06,
      "loss": 0.0551,
      "step": 5750
    },
    {
      "epoch": 0.620254518233344,
      "grad_norm": 2.235490322113037,
      "learning_rate": 4.01310586374421e-06,
      "loss": 0.0914,
      "step": 5800
    },
    {
      "epoch": 0.6256015399422522,
      "grad_norm": 0.08164875954389572,
      "learning_rate": 3.956615071743306e-06,
      "loss": 0.0611,
      "step": 5850
    },
    {
      "epoch": 0.6309485616511603,
      "grad_norm": 1.9488111734390259,
      "learning_rate": 3.900124279742402e-06,
      "loss": 0.0607,
      "step": 5900
    },
    {
      "epoch": 0.6362955833600684,
      "grad_norm": 3.013580083847046,
      "learning_rate": 3.8436334877414985e-06,
      "loss": 0.0728,
      "step": 5950
    },
    {
      "epoch": 0.6416426050689766,
      "grad_norm": 0.2795487344264984,
      "learning_rate": 3.7871426957405945e-06,
      "loss": 0.0401,
      "step": 6000
    },
    {
      "epoch": 0.6469896267778847,
      "grad_norm": 0.03139999881386757,
      "learning_rate": 3.730651903739691e-06,
      "loss": 0.0428,
      "step": 6050
    },
    {
      "epoch": 0.6523366484867928,
      "grad_norm": 0.08829857409000397,
      "learning_rate": 3.674161111738787e-06,
      "loss": 0.0561,
      "step": 6100
    },
    {
      "epoch": 0.657683670195701,
      "grad_norm": 0.10551551729440689,
      "learning_rate": 3.617670319737883e-06,
      "loss": 0.0966,
      "step": 6150
    },
    {
      "epoch": 0.6630306919046092,
      "grad_norm": 0.04397740960121155,
      "learning_rate": 3.561179527736979e-06,
      "loss": 0.0246,
      "step": 6200
    },
    {
      "epoch": 0.6683777136135173,
      "grad_norm": 0.026829872280359268,
      "learning_rate": 3.5046887357360754e-06,
      "loss": 0.0438,
      "step": 6250
    },
    {
      "epoch": 0.6737247353224254,
      "grad_norm": 0.02847275510430336,
      "learning_rate": 3.4481979437351714e-06,
      "loss": 0.0621,
      "step": 6300
    },
    {
      "epoch": 0.6790717570313336,
      "grad_norm": 0.08402439951896667,
      "learning_rate": 3.3917071517342677e-06,
      "loss": 0.0275,
      "step": 6350
    },
    {
      "epoch": 0.6844187787402417,
      "grad_norm": 0.02667413465678692,
      "learning_rate": 3.3352163597333637e-06,
      "loss": 0.0548,
      "step": 6400
    },
    {
      "epoch": 0.6897658004491498,
      "grad_norm": 0.011729631572961807,
      "learning_rate": 3.2787255677324596e-06,
      "loss": 0.0657,
      "step": 6450
    },
    {
      "epoch": 0.6951128221580579,
      "grad_norm": 0.04267070069909096,
      "learning_rate": 3.222234775731556e-06,
      "loss": 0.0096,
      "step": 6500
    },
    {
      "epoch": 0.7004598438669661,
      "grad_norm": 0.03566373139619827,
      "learning_rate": 3.165743983730652e-06,
      "loss": 0.0548,
      "step": 6550
    },
    {
      "epoch": 0.7058068655758742,
      "grad_norm": 0.03772609680891037,
      "learning_rate": 3.109253191729748e-06,
      "loss": 0.1207,
      "step": 6600
    },
    {
      "epoch": 0.7111538872847823,
      "grad_norm": 0.03282419219613075,
      "learning_rate": 3.0527623997288446e-06,
      "loss": 0.055,
      "step": 6650
    },
    {
      "epoch": 0.7165009089936906,
      "grad_norm": 0.03687657043337822,
      "learning_rate": 2.996271607727941e-06,
      "loss": 0.0393,
      "step": 6700
    },
    {
      "epoch": 0.7218479307025987,
      "grad_norm": 0.0310041680932045,
      "learning_rate": 2.939780815727037e-06,
      "loss": 0.0528,
      "step": 6750
    },
    {
      "epoch": 0.7271949524115068,
      "grad_norm": 0.03647968918085098,
      "learning_rate": 2.883290023726133e-06,
      "loss": 0.0326,
      "step": 6800
    },
    {
      "epoch": 0.7325419741204149,
      "grad_norm": 0.09737130999565125,
      "learning_rate": 2.8267992317252292e-06,
      "loss": 0.0263,
      "step": 6850
    },
    {
      "epoch": 0.7378889958293231,
      "grad_norm": 0.08388427644968033,
      "learning_rate": 2.770308439724325e-06,
      "loss": 0.0407,
      "step": 6900
    },
    {
      "epoch": 0.7432360175382312,
      "grad_norm": 0.06228946894407272,
      "learning_rate": 2.713817647723421e-06,
      "loss": 0.0439,
      "step": 6950
    },
    {
      "epoch": 0.7485830392471393,
      "grad_norm": 0.01879074238240719,
      "learning_rate": 2.6573268557225175e-06,
      "loss": 0.0631,
      "step": 7000
    },
    {
      "epoch": 0.7539300609560475,
      "grad_norm": 0.03870303928852081,
      "learning_rate": 2.6008360637216134e-06,
      "loss": 0.0258,
      "step": 7050
    },
    {
      "epoch": 0.7592770826649556,
      "grad_norm": 0.011592714115977287,
      "learning_rate": 2.5443452717207094e-06,
      "loss": 0.0576,
      "step": 7100
    },
    {
      "epoch": 0.7646241043738637,
      "grad_norm": 0.08115405589342117,
      "learning_rate": 2.4878544797198057e-06,
      "loss": 0.0888,
      "step": 7150
    },
    {
      "epoch": 0.7699711260827719,
      "grad_norm": 0.02739621326327324,
      "learning_rate": 2.431363687718902e-06,
      "loss": 0.046,
      "step": 7200
    },
    {
      "epoch": 0.7753181477916801,
      "grad_norm": 0.061706606298685074,
      "learning_rate": 2.374872895717998e-06,
      "loss": 0.0264,
      "step": 7250
    },
    {
      "epoch": 0.7806651695005882,
      "grad_norm": 0.08430298417806625,
      "learning_rate": 2.3183821037170944e-06,
      "loss": 0.0552,
      "step": 7300
    },
    {
      "epoch": 0.7860121912094963,
      "grad_norm": 0.051831748336553574,
      "learning_rate": 2.2618913117161903e-06,
      "loss": 0.0483,
      "step": 7350
    },
    {
      "epoch": 0.7913592129184045,
      "grad_norm": 0.14259597659111023,
      "learning_rate": 2.2054005197152867e-06,
      "loss": 0.0449,
      "step": 7400
    },
    {
      "epoch": 0.7967062346273126,
      "grad_norm": 0.2377268224954605,
      "learning_rate": 2.1489097277143826e-06,
      "loss": 0.033,
      "step": 7450
    },
    {
      "epoch": 0.8020532563362207,
      "grad_norm": 1.0359296798706055,
      "learning_rate": 2.092418935713479e-06,
      "loss": 0.0585,
      "step": 7500
    },
    {
      "epoch": 0.8074002780451288,
      "grad_norm": 0.04468629136681557,
      "learning_rate": 2.035928143712575e-06,
      "loss": 0.0501,
      "step": 7550
    },
    {
      "epoch": 0.812747299754037,
      "grad_norm": 0.06680723279714584,
      "learning_rate": 1.979437351711671e-06,
      "loss": 0.0587,
      "step": 7600
    },
    {
      "epoch": 0.8180943214629451,
      "grad_norm": 0.011988593265414238,
      "learning_rate": 1.9229465597107676e-06,
      "loss": 0.0478,
      "step": 7650
    },
    {
      "epoch": 0.8234413431718532,
      "grad_norm": 0.016833098605275154,
      "learning_rate": 1.8664557677098636e-06,
      "loss": 0.0445,
      "step": 7700
    },
    {
      "epoch": 0.8287883648807615,
      "grad_norm": 0.08186306059360504,
      "learning_rate": 1.8099649757089597e-06,
      "loss": 0.0399,
      "step": 7750
    },
    {
      "epoch": 0.8341353865896696,
      "grad_norm": 0.047196321189403534,
      "learning_rate": 1.7534741837080557e-06,
      "loss": 0.0915,
      "step": 7800
    },
    {
      "epoch": 0.8394824082985777,
      "grad_norm": 0.09476536512374878,
      "learning_rate": 1.6969833917071518e-06,
      "loss": 0.1018,
      "step": 7850
    },
    {
      "epoch": 0.8448294300074858,
      "grad_norm": 0.1626507043838501,
      "learning_rate": 1.640492599706248e-06,
      "loss": 0.0578,
      "step": 7900
    },
    {
      "epoch": 0.850176451716394,
      "grad_norm": 0.028925200924277306,
      "learning_rate": 1.5840018077053443e-06,
      "loss": 0.0336,
      "step": 7950
    },
    {
      "epoch": 0.8555234734253021,
      "grad_norm": 0.22614482045173645,
      "learning_rate": 1.5275110157044405e-06,
      "loss": 0.0337,
      "step": 8000
    },
    {
      "epoch": 0.8608704951342102,
      "grad_norm": 0.06386682391166687,
      "learning_rate": 1.4710202237035364e-06,
      "loss": 0.0377,
      "step": 8050
    },
    {
      "epoch": 0.8662175168431184,
      "grad_norm": 0.08052459359169006,
      "learning_rate": 1.4145294317026326e-06,
      "loss": 0.0409,
      "step": 8100
    },
    {
      "epoch": 0.8715645385520265,
      "grad_norm": 0.06822529435157776,
      "learning_rate": 1.3580386397017287e-06,
      "loss": 0.0534,
      "step": 8150
    },
    {
      "epoch": 0.8769115602609346,
      "grad_norm": 0.07861645519733429,
      "learning_rate": 1.3015478477008247e-06,
      "loss": 0.0149,
      "step": 8200
    },
    {
      "epoch": 0.8822585819698427,
      "grad_norm": 0.0565294586122036,
      "learning_rate": 1.245057055699921e-06,
      "loss": 0.0786,
      "step": 8250
    },
    {
      "epoch": 0.887605603678751,
      "grad_norm": 0.05624909698963165,
      "learning_rate": 1.1885662636990172e-06,
      "loss": 0.038,
      "step": 8300
    },
    {
      "epoch": 0.8929526253876591,
      "grad_norm": 0.04028172418475151,
      "learning_rate": 1.1320754716981133e-06,
      "loss": 0.0689,
      "step": 8350
    },
    {
      "epoch": 0.8982996470965672,
      "grad_norm": 0.09237176179885864,
      "learning_rate": 1.0755846796972095e-06,
      "loss": 0.0244,
      "step": 8400
    },
    {
      "epoch": 0.9036466688054754,
      "grad_norm": 0.05245332419872284,
      "learning_rate": 1.0190938876963054e-06,
      "loss": 0.0398,
      "step": 8450
    },
    {
      "epoch": 0.9089936905143835,
      "grad_norm": 0.04061834514141083,
      "learning_rate": 9.626030956954018e-07,
      "loss": 0.027,
      "step": 8500
    },
    {
      "epoch": 0.9143407122232916,
      "grad_norm": 0.048730261623859406,
      "learning_rate": 9.061123036944978e-07,
      "loss": 0.0712,
      "step": 8550
    },
    {
      "epoch": 0.9196877339321997,
      "grad_norm": 0.07057896256446838,
      "learning_rate": 8.496215116935941e-07,
      "loss": 0.0711,
      "step": 8600
    },
    {
      "epoch": 0.9250347556411079,
      "grad_norm": 0.10276251286268234,
      "learning_rate": 7.931307196926902e-07,
      "loss": 0.0697,
      "step": 8650
    },
    {
      "epoch": 0.930381777350016,
      "grad_norm": 0.11969465017318726,
      "learning_rate": 7.366399276917863e-07,
      "loss": 0.0662,
      "step": 8700
    },
    {
      "epoch": 0.9357287990589241,
      "grad_norm": 0.7626452445983887,
      "learning_rate": 6.801491356908825e-07,
      "loss": 0.0859,
      "step": 8750
    },
    {
      "epoch": 0.9410758207678324,
      "grad_norm": 0.02431509643793106,
      "learning_rate": 6.236583436899786e-07,
      "loss": 0.022,
      "step": 8800
    },
    {
      "epoch": 0.9464228424767405,
      "grad_norm": 0.12152031809091568,
      "learning_rate": 5.671675516890747e-07,
      "loss": 0.0251,
      "step": 8850
    },
    {
      "epoch": 0.9517698641856486,
      "grad_norm": 0.02571934461593628,
      "learning_rate": 5.106767596881709e-07,
      "loss": 0.0822,
      "step": 8900
    },
    {
      "epoch": 0.9571168858945567,
      "grad_norm": 0.08017879724502563,
      "learning_rate": 4.54185967687267e-07,
      "loss": 0.0616,
      "step": 8950
    },
    {
      "epoch": 0.9624639076034649,
      "grad_norm": 0.13764306902885437,
      "learning_rate": 3.976951756863631e-07,
      "loss": 0.0414,
      "step": 9000
    },
    {
      "epoch": 0.967810929312373,
      "grad_norm": 0.09531275182962418,
      "learning_rate": 3.4120438368545927e-07,
      "loss": 0.022,
      "step": 9050
    },
    {
      "epoch": 0.9731579510212811,
      "grad_norm": 0.021148335188627243,
      "learning_rate": 2.847135916845555e-07,
      "loss": 0.0981,
      "step": 9100
    },
    {
      "epoch": 0.9785049727301893,
      "grad_norm": 0.020375587046146393,
      "learning_rate": 2.2822279968365157e-07,
      "loss": 0.0463,
      "step": 9150
    },
    {
      "epoch": 0.9838519944390974,
      "grad_norm": 0.03351825103163719,
      "learning_rate": 1.7173200768274772e-07,
      "loss": 0.0838,
      "step": 9200
    },
    {
      "epoch": 0.9891990161480055,
      "grad_norm": 0.09123960882425308,
      "learning_rate": 1.1524121568184387e-07,
      "loss": 0.0366,
      "step": 9250
    },
    {
      "epoch": 0.9945460378569136,
      "grad_norm": 0.06093425303697586,
      "learning_rate": 5.8750423680940016e-08,
      "loss": 0.0412,
      "step": 9300
    },
    {
      "epoch": 0.9998930595658219,
      "grad_norm": 0.05003087595105171,
      "learning_rate": 2.2596316800361544e-09,
      "loss": 0.0318,
      "step": 9350
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9503796385413324,
      "eval_f1": 0.9561560994047057,
      "eval_loss": 0.19673468172550201,
      "eval_precision": 0.9656455768680218,
      "eval_recall": 0.9468513146813886,
      "eval_runtime": 2351.2171,
      "eval_samples_per_second": 7.954,
      "eval_steps_per_second": 0.249,
      "step": 9351
    }
  ],
  "logging_steps": 50,
  "max_steps": 9351,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4954744345629696.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
